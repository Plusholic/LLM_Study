Large Language Models 관련 논문 정리

## Red Teaming

1. [Red Teaming Language Models to Reduce Harms:Methods, Scaling Behaviors, and Lessons Learned](papers/Red_Teaming_Language_Models_to_Reduce_Harms/contents.md)
    <details>
    <summary>3 LINE SUMMARY</summary>
        - AI가 편견, 공격적 출력, 개인정보 유출 등 다양한 해로운 행동을 생성할 수 있기 때문에 레드팀을 활용함
        - Plane LM, Prompted LM, Rejection Sampling, Reinforcement Learning 등 모델 크기와 모델 형태에 따라 공격 성공률 측정
        - 언어모델이 생성할 수 있는 해로운 출력을 식별하고, 완화하기 위하여 레드팀 활동은 중요함
    </details>

2. [Red Teaming Language Models with Language Models](papers/Red_Teaming_Language_Models_with_Language_Models/contents.md)
3. [Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations](papers/Llama%20Guard/contents.md)
4. [AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs]



## Prompt

1. [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](papers/CoT.md)
2. [Graph Prompting]

## Fine Tuning
1. [PEFT of LLaMA for the Clinical Domain](papers/PEFT%20of%20LLaMA%20for%20the%20Clinical%20Domain/contents.md)

## Methods
1. [Retrieval-Augmented Generation for Knoledge-Intensive NLP Task](./papers/Retrieval-Augmented%20Generation%20for%20Knowledge-Intensive%20NLP%20Tasks/contents.md)
2. [PEFT]
3. [Bytepair Encoding]
4. 

## Models

1. [LIMA](./papers/LIMA/contents.md)
2. [OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework](./papers/OpenELM/contents.md)
2. [LLaMA2]
3. [Qwen]
4. [FLAN T5]
6. [vicuna]
7. [GPT-1]
8. [GPT-2]
9. [HyperCLOVA X Technical Report]
10. [vicuna]
11. [Mistral 7B]
12. [BERT]

## Recommendation System

1. [A Survey on Large Language Models for Recommendation](papers/A_Survey_on_LLMs_for_Recommendation.md)

## Quantization

## Reviews

## Dataset