from typing import Set
import time
from backend.core import run_llm
import streamlit as st
from streamlit_chat import message


# >> streamlit run app.py
# ì—¬ê¸°ì— page ì¶”ê°€í•˜ê³ ì‹¶ìŒ. -> done
# sidebarë¡œ Notion, Papers ë“± ì„ íƒí•  ìˆ˜ ìˆê²Œ ë§Œë“¤ê¸° -> done
# Notion API ë¡œ ëŒ€ë‹µí•˜ëŠ” ì±—ë´‡ ë§Œë“¤ê¸° -> done
# Excel Baseë¡œ ëŒ€ë‹µí•˜ëŠ” ì±—ë´‡ ë§Œë“¤ê¸° 
# PPT Baseë¡œ ëŒ€ë‹µí•˜ëŠ” ì±—ë´‡ ë§Œë“¤ê¸° 
# ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê²Œ í•˜ë ¤ë©´, run_llm ì—ì„œ queryì— ë­”ê°€ë¥¼ ì¶”ê°€í•´ì¤˜ì•¼ í•˜ë‚˜..?
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¶”ê°€. -> done

def create_sources_string(source_urls: Set[str]) -> str:
    if not source_urls:
        return ""
    sources_list = list(source_urls)
    sources_list.sort()
    sources_string = "reference sources:\n"
    # sources_page = "page:\n"
    
    for i, source in enumerate(sources_list):
        sources_string += f"{i+1}. Path : {source[0]}\n Page : {source[1]}\n"
        
    return sources_string


st.header("Plusholic Knowledge Database")
st.markdown("---")

if "user_prompt_history" not in st.session_state:
    st.session_state["user_prompt_history"] = []

if "chat_answers_history" not in st.session_state:
    st.session_state["chat_answers_history"] = []
    
# if "messages" not in st.session_state.keys(): # Initialize the chat message history
#     st.session_state.messages = [
#         {"role": "assistant", "content": "Ask me a question about Graph Neural Network!"}
#     ]
#     with st.chat_message(st.session_state.messages[0]["role"]):
#         st.write(st.session_state.messages[0]["content"])


with st.sidebar:
    st.title('ğŸ¤—ğŸ’¬ Plusholic Data Chat')
    
    # st.checkbox("Disable selectbox widget", key="disabled")
    db_type = st.radio(
                "Select Database Type ğŸ‘‰",
                key="visibility",
                options=["PDF papers", "Notion", "Excel", "PPT"],
                )
   
    # ìê²©ì¦ëª… ì°½ ì¶”ê°€
    # if ('EMAIL' in st.secrets) and ('PASS' in st.secrets):
    #     st.success('HuggingFace Login credentials already provided!', icon='âœ…')
    #     hf_email = st.secrets['EMAIL']
    #     hf_pass = st.secrets['PASS']
    # else:
    #     hf_email = st.text_input('Enter E-mail:', type='password')
    #     hf_pass = st.text_input('Enter password:', type='password')
    #     if not (hf_email and hf_pass):
    #         st.warning('Please enter your credentials!', icon='âš ï¸')
    #     else:
    #         st.success('Proceed to entering your prompt message!', icon='ğŸ‘‰')
    # st.markdown('ğŸ“– Learn how to build this app in this [blog](https://blog.streamlit.io/how-to-build-an-llm-powered-chatbot-with-streamlit/)!')

# Database Typeì„ PDF Papersë¡œ í–ˆë‹¤ë©´,
if db_type == "PDF papers":
        
    st.title("Chat With Graph Neural Network References")

    if "messages" not in st.session_state.keys(): # Initialize the chat message history
        st.session_state.messages = [
            # {"role": "assistant", "content": "Ask me a question about Graph Neural Network!"}
        ]
        st.session_state.messages.append({"role": "assistant", "content": "Ask me a question about Graph Neural Network!"})

        with st.chat_message(st.session_state.messages[0]["role"]):
            # st.write(st.session_state.messages[0]["content"])
            st.markdown(st.session_state.messages[0]["content"])
            # ì—¬ê¸°ì— ì¶”ê°€
            
    # ë§Œì•½ í”„ë¡¬í”„íŠ¸ê°€ ë“¤ì–´ì˜¤ë©´ ë‹¤ìŒ ë‚´ìš©ì„ ì‹¤í–‰.
    if prompt := st.chat_input("Enter your question"):

        # ì´ì „ ë©”ì„¸ì§€ë“¤ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])
                # st.markdown(message["content"])

        # ë‚´ê°€ ì…ë ¥í•œ ë©”ì„¸ì§€ê°€ ë¨¼ì € ë‚˜ì˜¤ë„ë¡ ì„¸íŒ…
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message(st.session_state.messages[-1]["role"]):
            # st.write(st.session_state.messages[-1]["content"])
            st.markdown(st.session_state.messages[-1]["content"])
        # ë‹µë³€ì„ ìƒì„±í• ë•Œ ìŠ¤í”¼ë„ˆê°€ ëŒì•„ê°€ë„ë¡ ì„¸íŒ…
        with st.spinner("Thinking..."):
            generated_response = run_llm(query=prompt) 

        # ë©”ì„¸ì§€ê°€ ì±—ë´‡ìœ¼ë¡œë¶€í„° ì˜¨ê²Œ ì•„ë‹ˆë¼ë©´ -> ìœ ì €ë¡œë¶€í„° ì˜¨ê±°ë¼ë©´, ì‘ë‹µì„ ìƒì„±í•¨
        if st.session_state.messages[-1]["role"] != "assistant":
            
            # with chat_message() -> ì±„íŒ…ì°½ì—ì„œ streamlitì˜ ë´‡ í”„ë¡œí•„ê°™ì€ê±° ë‚˜ì˜¤ê²Œí•¨
            with st.chat_message("assistant"):
                    # ë‹µë³€ ìƒì„±
                    sources = set([(doc.metadata['source'], doc.metadata['page']) for doc in generated_response["source_documents"]])
                    # formatted_response = (f"{generated_response['result']} \n {create_sources_string(sources)}")
                    # formatted_response = (f"{generated_response['answer']} \n {create_sources_string(sources)}")

                    # formatted response ë¼ëŠ” ë§ë„ í•„ìš” ì—†ëŠ”ê±°ê°™ì€ë°? ì´ê±° ë°”ê¾¸ì
                    formatted_response = (f"{generated_response['answer']}")
                    
                    # st.write(formatted_response)
                    
                    full_response = ""
                    message_placeholder = st.empty()
                    
                    # ë‹µë³€ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° -> OpenAIì—ì„œ streaming=True ì¼ ë•Œ ì–´ë–»ê²Œ ì“°ëŠ”ì§€ ë‚˜ì¤‘ì— ì¶”ê°€
                    for idx, chunk in enumerate(formatted_response.split()):  
                        full_response += chunk + " "
                        time.sleep(0.05)
                        message_placeholder.markdown(full_response + "â–Œ")
                        prev_chunk = chunk
                    full_response += create_sources_string(sources)
                    
                    # full_response += formatted_response
                    # full_response += create_sources_string(sources)
                    message_placeholder.markdown(full_response)
                    st.session_state.messages.append({"role": "assistant", "content": full_response}) # Add response to message history


        # session_stateì— ì§ˆë¬¸ê³¼ ë‹µë³€ ì €ì¥
        st.session_state["user_prompt_history"].append(prompt)
        st.session_state["chat_answers_history"].append(formatted_response)

elif db_type == "Notion":
    
    st.title("Chat With Graph Neural Network References")
    st.write('You Must select PDF papers')
    st.write('You current selected:', db_type)

elif db_type == "Excel":

    st.title("Chat With Graph Neural Network References")
    st.write('You Must select PDF papers')
    st.write('You current selected:', db_type)
    
elif db_type == "PPT":

    st.title("Chat With Graph Neural Network References")
    st.write('You Must select PDF papers')
    st.write('You current selected:', db_type)