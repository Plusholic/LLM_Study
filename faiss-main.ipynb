{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid parent xref., rebuild xref\n",
      "Multiple definitions in dictionary at byte 0x587b8 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x58cb2 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x58e64 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x59116 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x593cd for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5979f for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x59ad2 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x59f54 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5a137 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5a2ea for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5a475 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5a618 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5a803 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5ab12 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5adfc for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5b2c6 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5b6c1 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5ba97 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5bd83 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5c042 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5c30a for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5c5e4 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5c8a3 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5cb98 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5ce60 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5d11f for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5d360 for key /MediaBox\n",
      "incorrect startxref pointer(1)\n",
      "Created a chunk of size 1142, which is longer than the specified 1000\n",
      "Created a chunk of size 1372, which is longer than the specified 1000\n",
      "Created a chunk of size 1510, which is longer than the specified 1000\n",
      "Created a chunk of size 1109, which is longer than the specified 1000\n",
      "Created a chunk of size 1024, which is longer than the specified 1000\n",
      "Created a chunk of size 1568, which is longer than the specified 1000\n",
      "Created a chunk of size 1067, which is longer than the specified 1000\n",
      "Created a chunk of size 1637, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1906, which is longer than the specified 1000\n",
      "Created a chunk of size 3378, which is longer than the specified 1000\n",
      "Created a chunk of size 1068, which is longer than the specified 1000\n",
      "Created a chunk of size 1367, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1483, which is longer than the specified 1000\n",
      "Created a chunk of size 1358, which is longer than the specified 1000\n",
      "Created a chunk of size 1866, which is longer than the specified 1000\n",
      "Created a chunk of size 1709, which is longer than the specified 1000\n",
      "Created a chunk of size 1368, which is longer than the specified 1000\n",
      "Created a chunk of size 1649, which is longer than the specified 1000\n",
      "Created a chunk of size 1402, which is longer than the specified 1000\n",
      "Created a chunk of size 1530, which is longer than the specified 1000\n",
      "Created a chunk of size 1655, which is longer than the specified 1000\n",
      "Created a chunk of size 1636, which is longer than the specified 1000\n",
      "Created a chunk of size 1622, which is longer than the specified 1000\n",
      "Created a chunk of size 1422, which is longer than the specified 1000\n",
      "Created a chunk of size 1463, which is longer than the specified 1000\n",
      "Created a chunk of size 2561, which is longer than the specified 1000\n",
      "Created a chunk of size 1796, which is longer than the specified 1000\n",
      "Created a chunk of size 1732, which is longer than the specified 1000\n",
      "Created a chunk of size 3664, which is longer than the specified 1000\n",
      "Created a chunk of size 1433, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n",
      "Created a chunk of size 1433, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n",
      "Created a chunk of size 1061, which is longer than the specified 1000\n",
      "Created a chunk of size 1082, which is longer than the specified 1000\n",
      "Created a chunk of size 1017, which is longer than the specified 1000\n",
      "Created a chunk of size 1111, which is longer than the specified 1000\n",
      "Created a chunk of size 1106, which is longer than the specified 1000\n",
      "Created a chunk of size 1111, which is longer than the specified 1000\n",
      "Created a chunk of size 1024, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# from langchain.document_loaders import PyPDFLoader\n",
    "# from langchain.document_loaders import ReadTheDocsLoader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"hi\")\n",
    "    # pdf_file = \"/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/A GNN RNN Approach for Harnessing Geospatial and Temporal Information Application to Crop Yeild Prediction.pdf\"\n",
    "    gnn_path = \"/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/\"\n",
    "    # loader = PyPDFLoader(file_path=pdf_file)\n",
    "    # loader = ReadTheDocsLoader(path=gnn_path)\n",
    "    loader = PyPDFDirectoryLoader(path=gnn_path)\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=30, separator=\"\\n\")\n",
    "    docs = text_splitter.split_documents(documents=documents)\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    vectorstore.save_local(\"faiss_index_react\")\n",
    "    \n",
    "    new_vectorstore = FAISS.load_local(\"faiss_index_react\", embeddings)\n",
    "    \n",
    "    qa = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
    "                                     chain_type='refine',\n",
    "                                     retriever = new_vectorstore.as_retriever(),\n",
    "                                     return_source_documents=True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Give me the gist of Graph Attention Network(GAT) in 3 sentences. Tell me you don't know if you don't know.\"\n",
    "# query = \"Give me the gist of DropEdge and github adress. Tell me you don't know if you don't know.\"\n",
    "# query = \"Give me the gist of Body Composition. Based on a given context, tell me you don't know if you don't know.\"\n",
    "query = \"Sahai가 2020년에 쓴 논문 제목 알려줘. 만약 주어진 문맥에 기초해서 답을 하기 어려우면, 모른다고 말해줘.\"\n",
    "res = qa({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sahai가 2020년에 쓴 논문 제목 알려줘. 만약 주어진 문맥에 기초해서 답을 하기 어려우면, 모른다고 말해줘.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nI'm sorry, but I don't know the title of the paper written by Sahai et al. in 2020, which was published in Diabetes &Metabolic Syndrome: Clinical Research &Reviews and based on authors' own computation.\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Source: Authors ’own computation.A.K. Sahai et al. / Diabetes &Metabolic Syndrome: Clinical Research &Reviews 14 (2020) 1419 e1427 1422'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['source_documents'][2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/ARIMA modelling & forecasting of COVID-19 in top five affected countries.pdf',\n",
       " 'page': 3}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['source_documents'][2].metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('LLM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a3a50cfa768e55079b834244adbc23d62a4b24bbd2f8b443e30bd8c79d3f7ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
