{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# from langchain.document_loaders import ReadTheDocsLoader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from langchain.retrievers import BM25Retriever, TFIDFRetriever, EnsembleRetriever\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS, Chroma\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid parent xref., rebuild xref\n",
      "Multiple definitions in dictionary at byte 0x587b8 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x58cb2 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x58e64 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x59116 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x593cd for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5979f for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x59ad2 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x59f54 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5a137 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5a2ea for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5a475 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5a618 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5a803 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5ab12 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5adfc for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5b2c6 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5b6c1 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5ba97 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5bd83 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5c042 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5c30a for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5c5e4 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5c8a3 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5cb98 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5ce60 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5d11f for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x5d360 for key /MediaBox\n",
      "incorrect startxref pointer(1)\n",
      "/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# pdf_file = \"/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/A GNN RNN Approach for Harnessing Geospatial and Temporal Information Application to Crop Yeild Prediction.pdf\"\n",
    "gnn_path = \"/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/\"\n",
    "loader = PyPDFDirectoryLoader(path=gnn_path)\n",
    "documents = loader.load()\n",
    "chunk_size = 128\n",
    "\n",
    "sentence_splitter = SentenceTransformersTokenTextSplitter(\n",
    "    chunk_overlap = 30,\n",
    "    model_name = 'sentence-transformers/all-mpnet-base-v2',\n",
    "    tokens_per_chunk=chunk_size\n",
    ")\n",
    "\n",
    "docs = sentence_splitter.split_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector db\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "vectorstore.save_local(f\"./Retrieval_Database/Vector_Database/paper_faiss_openai_{chunk_size}_sentence_splitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword search\n",
    "keyword_store = BM25Retriever.from_documents(docs)\n",
    "with open(f\"./Retrieval_Database/Keyword_Database/paper_BM25_{chunk_size}_sentence_splitter.pkl\", 'wb') as f:\n",
    "    pickle.dump(keyword_store, f)\n",
    "\n",
    "keyword_store = TFIDFRetriever.from_documents(docs)\n",
    "keyword_store.save_local(f\"./Retrieval_Database/Keyword_Database/paper_TDIDF_{chunk_size}_sentence_splitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "paper_vectorstore = FAISS.load_local(f\"./Retrieval_Database/Vector_Database/paper_faiss_openai_{chunk_size}_sentence_splitter\", embeddings)\n",
    "paper_tdidf = TFIDFRetriever.load_local(f\"./Retrieval_Database/Keyword_Database/paper_TDIDF_{chunk_size}_sentence_splitter\")\n",
    "with open (f\"./Retrieval_Database/Keyword_Database/paper_BM25_{chunk_size}_sentence_splitter.pkl\", 'rb') as f:\n",
    "    paper_bm25 = pickle.load(f)\n",
    "\n",
    "paper_info_retriever = Chroma(embedding_function=embeddings,\n",
    "                              persist_directory='./Retrieval_Database/Vector_Database/paper_info_chroma_openai_128_sentence_splitter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ensemble retriever\n",
    "paper_ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        paper_vectorstore.as_retriever(),\n",
    "        paper_tdidf,\n",
    "        paper_bm25\n",
    "                ],\n",
    "    weights=[0.5, 0.25, 0.25]\n",
    ")\n",
    "\n",
    "paper_retrieval_tool = create_retriever_tool(\n",
    "    retriever   = paper_ensemble_retriever,\n",
    "    name        = \"Search_GNN_Papers\",\n",
    "    description = \"Searches and returns papers regarding the GNN.\",\n",
    ")\n",
    "\n",
    "paper_info_retrieval_tool = create_retriever_tool(\n",
    "    retriever   = paper_info_retriever.as_retriever(),\n",
    "    name        = \"Search_GNN_Papers_info\",\n",
    "    description = \"Searches and returns papers regarding the information\",\n",
    ")\n",
    "\n",
    "tools = [paper_retrieval_tool, paper_info_retrieval_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"Answer the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"agent_scratchpad\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=OpenAI(temperature=0),\n",
    "                     prompt=prompt)\n",
    "\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain,\n",
    "                      tools=tools,\n",
    "                      )\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: DropEdge is a graph neural network (GNN) technique\n",
      "Action: Search_GNN_Papers\n",
      "Action Input: DropEdge\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[Document(page_content='in network depth. this paper proposes dropedge, a novel and ﬂexible technique to alleviate both issues. at its core, dropedge randomly removes a certain number of edges from the input graph at each training epoch, acting like a data augmenter and also a message passing reducer. furthermore, we theoretically demonstrate that dropedge either reduces the convergence speed of over - smoothing or relieves the information loss caused by it. more importantly, our dropedge is a general skill that can be equipped with many other backbone models ( e. g. gcn, resgcn, graphsage, and jknet ) for enhanced', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/DropEdge.pdf', 'page': 0}), Document(page_content='published as a conference paper at iclr 2020 matrix. as a reference, dropedge can be regarded as a generation of dropout from dropping feature dimensions to dropping edges, which mitigates both over - ﬁtting and over - smoothing. in fact, the impacts of dropout and dropedge are complementary to each other, and their compatibility will be shown in the experiments. dropedge vs. dropnode another related vein belongs to the kind of node sampling based methods, including graphsage ( hamilton et al., 2017 ), fastgcn ( chen et al., 2018 ), and as - gcn ( huang et', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/DropEdge.pdf', 'page': 5}), Document(page_content='##s on showing the beneﬁts of dropedge. 4. 1 m ethodology at each training epoch, the dropedge technique drops out a certain rate of edges of the input graph by random. formally, it randomly enforces vpnon - zero elements of the adjacency matrix ato be zeros, where vis the total number of edges and pis the dropping rate. if we denote the resulting adjacency matrix as adrop, then its relation with abecomes adrop = a−a ′, ( 2 ) wherea ′ is a sparse matrix expanded by a random subset of size vp', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/DropEdge.pdf', 'page': 3}), Document(page_content='##clusion we have presented dropedge, a novel and efﬁcient technique to facilitate the development of deep graph convolutional networks ( gcns ). by dropping out a certain rate of edges by random, dropedge includes more diversity into the input data to prevent over - ﬁtting, and reduces message passing in graph convolution to alleviate over - smoothing. considerable experiments on cora, citeseer, pubmed and reddit have veriﬁed that dropedge can generally and consistently promote the performance of current popular gcns, such as gcn, resgcn, jknet,', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/DropEdge.pdf', 'page': 8}), Document(page_content='frontiersin. org july 2021 | volume 9 | article 634156 17he et al. covid - 19 assessment and prediction', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/Risk Assessment and Prediction of COVID-19 Based on Epidemiological Data From Spatiotemporal Geography.pdf', 'page': 16}), Document(page_content='- 4 + dropedge gcn - 4 + dropedge inceptgcn - 4 + dropedge jknet - 4 + dropedge 0 25 50 75 100 125 150 175 200 epoch0. 81. 01. 21. 41. 61. 82. 0validation lossciteseer resgcn - 6 gcn - 6 inceptgcn - 6 jknet - 6 resgcn - 6 + dropedge gcn - 6 + dropedge inceptgcn - 6 + dropedge jknet - 6 + dropedge figure 6 : the validation loss on different backbones w and', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/DropEdge.pdf', 'page': 14}), Document(page_content='##gcn - 6 jknet - 6 resgcn - 6 + dropedge gcn - 6 + dropedge inceptgcn - 6 + dropedge jknet - 6 + dropedge 0 25 50 75 100 125 150 175 200 epoch0. 81. 01. 21. 41. 61. 82. 0validation lossciteseer resgcn - 4 gcn - 4 inceptgcn - 4 jknet - 4 resgcn - 4 + dropedge gcn - 4 + dropedge inceptgcn - 4 + dropedge jknet - 4 + dropedge', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/DropEdge.pdf', 'page': 14}), Document(page_content='( meunier et al., 2009 ), while cao et al. reported a linear downward trend ( cao et al., 2014b ). inthisregard, combiningotherfunctionalneuroimaging techniques, as well as performing structure - function studi es, will help elucidate the neural substrates underlying cognit ive and behavioral [UNK] during developmental stages ( shahetal., 2018 ). working memory performance and network efﬁciency workingmemoryisapsychologicalconstructforthetemporary storage and manipulation of the information required to frontiers in neuroscience | www', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/Application of Graph Theory for Identifying Connectivity Patterns in Human Brain Networks A systemic review.pdf', 'page': 13}), Document(page_content='dropedge on cora. 0 25 50 75 100 125 150 175 200 epoch0. 20. 40. 60. 81. 01. 21. 41. 6train & validation losscora gcn - 4 + dropedge : validation gcn - 4 + dropedge : train gcn - 4 + dropedge ( li ) : validation gcn - 4 + dropedge ( li ) : train ( b ) comparison between dropedge and layer - wise ( lw ) dropedge. figure 4 the number of layers grows ; it probably has successfully learned meaningful node representations after training, which could also be validated by', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/DropEdge.pdf', 'page': 8}), Document(page_content='increasing integration [UNK] ency ) before misses compared with hits and task - free rest, mostly i n the dmn areas and visual networks. these ﬁndings augment our understanding about the key role of the dmn in behavioral performance at rest and during a task ; however, its associati on with other brain regions in more complex cognitive tasks, such asreasoningandexecutivefunctions, requiresfurtherstud ies. behavioral performance in natural environments and everyday settings one of the fascinating areas of cognitive neuroscience in re cent years is neoroergonomics ; that is to say, the', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/Application of Graph Theory for Identifying Connectivity Patterns in Human Brain Networks A systemic review.pdf', 'page': 14}), Document(page_content='##dynamicnodalpropertieswit hin the dmn, they revealed the importance of the default network, especially the posterior cingulate areas, on human cognitive performance. finally, sadaghiani et al. ( 2015 ) investigated the relationshipbetweenongoingalterationsinbaselineconn ectivity patterns and behavioral performance through a continuous auditory detection task. interestingly, their results ind icated a reduction in modularity ( i. e., increasing integration [UNK] ency ) before misses compared with hits and task - free rest, mostly i n the dmn areas and visual networks. these', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/Application of Graph Theory for Identifying Connectivity Patterns in Human Brain Networks A systemic review.pdf', 'page': 14}), Document(page_content='##cn - 4 inceptgcn - 4 jknet - 4 resgcn - 4 + dropedge gcn - 4 + dropedge inceptgcn - 4 + dropedge jknet - 4 + dropedge ( b ) the validation loss on different backbones w and w / o dropedge. figure 2 table 2 : accuracy ( % ) comparisons with sotas. the number in parenthesis denotes the network depth for the models with dropedge. transductive inductive cora citeseer pubmed reddit gcn 86. 64 79. 34 90. 22 95. 68 fastgcn 85.', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/DropEdge.pdf', 'page': 7})]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The documents returned from the search provide information about DropEdge\n",
      "Action: Search_GNN_Papers_info\n",
      "Action Input: DropEdge\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m[Document(page_content='주제: Model\\n도메인: \\n논문명: DROPEDGE: TOWARDS DEEP GRAPH CONVOLU- TIONAL NETWORKS ON NODE CLASSIFICATION\\nIF:', metadata={'저널명': 'arXiv ', '행': '29'}), Document(page_content='주제: Dynamic Graph\\n도메인: \\n논문명: EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs\\nIF:', metadata={'저널명': 'The Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20) ', '행': '36'}), Document(page_content='주제: Graph Theory\\n도메인: Brain\\n논문명: A Graph Theory-Based Modeling of Functional Brain Connectivity Based on EEG: A Systematic Review in the Context of Neuroergonomics\\nIF: 4.34', metadata={'저널명': 'IEEE Access', '행': '12'}), Document(page_content='주제: Dynamic Graph\\n도메인: \\n논문명: SDG: A Simplified and Dynamic Graph Neural Network\\nIF:', metadata={'저널명': 'SIGIR ’21, July 11–15, 2021, Virtual Event, Canada ', '행': '60'})]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The documents returned from the search provide information about DropEdge's purpose and application\n",
      "Final Answer: DropEdge is a graph neural network technique that randomly removes a certain number of edges from the input graph at each training epoch, acting like a data augmenter and also a message passing reducer. It is used to prevent over-fitting and reduce over-smoothing, and can be applied to many popular GNN backbones such as GCN, ResGCN, GraphSAGE, and JKNet.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DropEdge is a graph neural network technique that randomly removes a certain number of edges from the input graph at each training epoch, acting like a data augmenter and also a message passing reducer. It is used to prevent over-fitting and reduce over-smoothing, and can be applied to many popular GNN backbones such as GCN, ResGCN, GraphSAGE, and JKNet.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=memory\n",
    ")\n",
    "\n",
    "agent_executor.run(\n",
    "    input=\"what is DropEdge?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Give me the gist of Graph Attention Network(GAT) in 3 sentences. Tell me you don't know if you don't know.\"\n",
    "# query = \"Give me the gist of DropEdge and github adress. Tell me you don't know if you don't know.\"\n",
    "# query = \"Give me the gist of Body Composition. Based on a given context, tell me you don't know if you don't know.\"\n",
    "query = \"Sahai's paper?\"\n",
    "res = qa({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sahai's paper?\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sahai did not write the paper.\n",
      "\n",
      "n. b., a. b., c. c., j. f., s. h., m. k., j. k., j. r., v. s., e. s., and h. j. s. wrote the paper. the authors declare no competing interest. this article is a pnas direct submission. published under the pnas license. 1j. l. and m. m. contributed equally to this work. 2to whom correspondence may be addressed. email : josef. ludescher @ pik - potsdam. de ormaria. martin @\n",
      "\n",
      "{'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/Network-based forecasting for climate phenomena.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(res['result'])\n",
    "print()\n",
    "print(res['source_documents'][1].page_content)\n",
    "print()\n",
    "print(res['source_documents'][1].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "sys.path.append('./')\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from typing import Any\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain, HypotheticalDocumentEmbedder, LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is DropEdge',\n",
       " 'chat_history': [HumanMessage(content='What is DropEdge'),\n",
       "  AIMessage(content='DropEdge is a technique that can be employed in conjunction with dropnode methods to further enhance their performance. This enhancement can be observed by referring to the increase in performance achieved by DropEdge for GraphSAGE in Table 1.5.2. DropEdge helps address the limitations of deep neural networks for graph data by mitigating overfitting and oversmoothing issues. Although the detailed analysis and evaluations of DropEdge and its variants are mainly focused on the Cora dataset, the technique has shown promising results. It is worth noting that DropEdge is not primarily concerned with pushing state-of-the-art results but rather aims to provide a deeper understanding of its effectiveness.')],\n",
       " 'answer': 'DropEdge is a technique that can be employed in conjunction with dropnode methods to further enhance their performance. This enhancement can be observed by referring to the increase in performance achieved by DropEdge for GraphSAGE in Table 1.5.2. DropEdge helps address the limitations of deep neural networks for graph data by mitigating overfitting and oversmoothing issues. Although the detailed analysis and evaluations of DropEdge and its variants are mainly focused on the Cora dataset, the technique has shown promising results. It is worth noting that DropEdge is not primarily concerned with pushing state-of-the-art results but rather aims to provide a deeper understanding of its effectiveness.',\n",
       " 'source_documents': [Document(page_content='in network depth. this paper proposes dropedge, a novel and ﬂexible technique to alleviate both issues. at its core, dropedge randomly removes a certain number of edges from the input graph at each training epoch, acting like a data augmenter and also a message passing reducer. furthermore, we theoretically demonstrate that dropedge either reduces the convergence speed of over - smoothing or relieves the information loss caused by it. more importantly, our dropedge is a general skill that can be equipped with many other backbone models ( e. g. gcn, resgcn, graphsage, and jknet ) for enhanced', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/DropEdge.pdf', 'page': 0}),\n",
       "  Document(page_content='published as a conference paper at iclr 2020 matrix. as a reference, dropedge can be regarded as a generation of dropout from dropping feature dimensions to dropping edges, which mitigates both over - ﬁtting and over - smoothing. in fact, the impacts of dropout and dropedge are complementary to each other, and their compatibility will be shown in the experiments. dropedge vs. dropnode another related vein belongs to the kind of node sampling based methods, including graphsage ( hamilton et al., 2017 ), fastgcn ( chen et al., 2018 ), and as - gcn ( huang et', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/DropEdge.pdf', 'page': 5}),\n",
       "  Document(page_content='actually, employing dropedge upon the dropnode methods further delivers promising enhancement, which can be checked by revisiting the increase by dropedge for graphsage in table 1. 5. 2 h ow does dropedge help? this section continues a more in - depth analysis on dropedge and attempts to ﬁgure out why it works. due to the space limit, we only provide the results on cora, and defer the evaluations on other datasets to the supplementary material. note that this section mainly focuses on analyzing dropedge and its variants, without the concern with pushing state - of - the - art results. so', metadata={'source': '/Users/jeonjunhwi/문서/Projects/GNN_Covid/refference/GNN논문/DropEdge.pdf', 'page': 6})]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"What is DropEdge\"\n",
    "k = 3\n",
    "threshold = 0.5\n",
    "    \n",
    "embeddings = OpenAIEmbeddings()\n",
    "# docsearch = FAISS.load_local(\"faiss_index_256\", embeddings)\n",
    "# docsearch = FAISS.load_local(\"faiss_openai_512_sentence_splitter\", embeddings)\n",
    "docsearch = FAISS.load_local(\"faiss_openai_128_sentence_splitter\", embeddings)\n",
    "# chat = ChatOpenAI(verbose=True, temperature=0)\n",
    "\n",
    "# 답을 찾을 수 없는 경우, 답을 찾을 수 없다고 말하고 자체 지식에 의존하세요 라는 내용 추가\n",
    "custom_template = \"\"\"\n",
    "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question. If you do not know the answer reply with 'I am sorry'.\n",
    "If you can't find an answer, say you can't find an answer and rely on your own knowledge.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "Answers:\"\"\"\n",
    "\n",
    "CUSTOM_QUESTION_PROMPT = PromptTemplate.from_template(custom_template)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",\n",
    "                                output_key = 'answer',\n",
    "                                return_messages=True)\n",
    "\n",
    "llm = llm=ChatOpenAI(verbose=True,\n",
    "                        temperature=0,\n",
    "                    #  streaming=True,\n",
    "                    #  callbacks=[StreamingStdOutCallbackHandler()]\n",
    "                    )\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever = docsearch.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\n",
    "            \"k\":k,\n",
    "            \"score_threshold\": threshold\n",
    "            }\n",
    "        ),\n",
    "    condense_question_prompt=CUSTOM_QUESTION_PROMPT,\n",
    "    return_source_documents=True,\n",
    "    chain_type='refine',\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "qa({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_template = \"\"\"\n",
    "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question. If you do not know the answer reply with 'I am sorry'.\n",
    "If you can't find an answer, say you can't find an answer and rely on your own knowledge.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "Answers:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"question\", \"chat_history\"], template=custom_template)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "bge_embeddings = OpenAIEmbeddings()\n",
    "embeddings = HypotheticalDocumentEmbedder(\n",
    "    llm_chain=llm_chain,\n",
    "    base_embeddings=bge_embeddings\n",
    ")\n",
    "\n",
    "result = embeddings.embed_query(\n",
    "    \"What is DropEdge?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('LLM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a3a50cfa768e55079b834244adbc23d62a4b24bbd2f8b443e30bd8c79d3f7ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
