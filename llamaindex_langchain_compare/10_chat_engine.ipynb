{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "llama_2_docs = SimpleDirectoryReader(input_files=['./assets/llama2.pdf'], filename_as_id=True).load_data()\n",
    "index = VectorStoreIndex.from_documents(llama_2_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 채팅 컨덴스 모드\n",
    "chat_engine = index.as_chat_engine(chat_mode=\"condense_question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 is a collection of pretrained and fine-tuned large language models (LLMs) that range in scale from 7 billion to 70 billion parameters. These models, specifically the Llama 2-Chat models, are optimized for dialogue use cases. They have been developed and released with the aim of outperforming open-source chat models on various benchmarks. The authors of Llama 2 provide a detailed description of their approach to fine-tuning and safety improvements in order to encourage the community to build on their work and contribute to the responsible development of LLMs.\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"What is Llama2?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 is a family of pretrained and fine-tuned models with scales ranging from 7 billion to 70 billion parameters. Its purpose is to serve as a competitive alternative to existing open-source chat models and even some proprietary models. While it may not be on par with models like GPT-4, Llama 2 has demonstrated its competitiveness and competency on evaluation sets. It is designed to align with the principles of helpfulness and safety. Llama 2 has been made available for both research and commercial use, and its release is part of an effort to encourage responsible AI innovation. By openly releasing Llama 2, the creators aim to foster collaboration and draw upon the collective wisdom and ingenuity of the AI community to improve and make the models safer. The ultimate goal is to democratize access to foundational models and stimulate innovation in the industry.\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"Can you tell me more?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리셋 하면 앞의 대화내용이 다 사라짐\n",
    "chat_engine.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_engine.chat(\"Can you tell me more?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but based on the provided context information, there is no additional information about the conversation available.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('llamaindex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f13b51dec9893a665284acd155bab776a7e14c668dd25de27de89f99a4571a06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
