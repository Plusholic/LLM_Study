{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.42.post1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import llama_index\n",
    "llama_index.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "# filename_as_id = True로 하면 node_id가 file_name_part_{num} 으로 설정됨\n",
    "llama2_doc = SimpleDirectoryReader(input_files=[\"./assets/llama2.pdf\"], filename_as_id=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "print(len(llama2_doc)) # 77 페이지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assets/llama2.pdf_part_0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama2_doc[0].node_id # node id가 경로로 설정됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.extractors import (\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor\n",
    ")\n",
    "\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "\n",
    "# documents를 chunking\n",
    "node_parser = SimpleNodeParser(separator=\" \", chunk_size=512, chunk_overlap=20, include_metadata=True)\n",
    "llama2_nodes = node_parser.get_nodes_from_documents(llama2_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='6e3f7640-4647-4da7-ba12-26f99f4dc5e6', embedding=None, metadata={'page_label': '1', 'file_name': 'llama2.pdf', 'file_path': 'assets/llama2.pdf', 'file_type': 'application/pdf', 'file_size': 13661300, 'creation_date': '2024-02-11', 'last_modified_date': '2023-12-16', 'last_accessed_date': '2024-02-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='assets/llama2.pdf_part_0', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '1', 'file_name': 'llama2.pdf', 'file_path': 'assets/llama2.pdf', 'file_type': 'application/pdf', 'file_size': 13661300, 'creation_date': '2024-02-11', 'last_modified_date': '2023-12-16', 'last_accessed_date': '2024-02-11'}, hash='9479873a161d4f1f6a832af9688cbd7b9ef978ea6512c749dc8071ff1bdeeab2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='794dc566-fcce-42d6-b7b0-c6d3a8fa7026', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1d7ecd29ba5382bb82a24175d43a6a8d2a59e2e48bc95f3093538efa6410ae42')}, text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.', start_char_idx=0, end_char_idx=1688, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama2_nodes[0] # ref_doc_id가 청킹되기 전 documents의 id로 설정됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assets/llama2.pdf_part_0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama2_nodes[0].ref_doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assets/llama2.pdf_part_4'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama2_nodes[10].ref_doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assets/llama2.pdf_part_39'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama2_nodes[100].ref_doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama2_nodes.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext, VectorStoreIndex\n",
    "\n",
    "# service_context = ServiceContext.from_defaults(node_parser=node_parser)\n",
    "index = VectorStoreIndex.from_documents(llama2_doc)#, service_context=service_context)\n",
    "index.storage_context.persist(persist_dir='./storage/cache/papers/llama2_node_id/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "Num of inserted/refreshed documents :  0\n"
     ]
    }
   ],
   "source": [
    "# ref_docs는 유지보수를 위해 필요할 것 같음\n",
    "# delete_from_docstore = True로 설정하면 docstore에서 새로운게 있으면 True로 반환됨. False로 반환되면 새로운 docs가 없는 것\n",
    "refreshed_docs = index.refresh_ref_docs(documents=llama2_doc, update_kwargs={\"delete_kwargs\":{\"delete_from_docstore\":True}})\n",
    "print(refreshed_docs)\n",
    "print(\"Num of inserted/refreshed documents : \", sum(refreshed_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "Num of inserted/refreshed documents :  26\n"
     ]
    }
   ],
   "source": [
    "# 경로에 다른 파일을 추가함\n",
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index import ServiceContext, VectorStoreIndex\n",
    "\n",
    "docs = SimpleDirectoryReader(\"./assets\", filename_as_id=True).load_data()\n",
    "refreshed_docs = index.refresh_ref_docs(documents=docs, update_kwargs={\"delete_kwargs\":{\"delete_from_docstore\":True}})\n",
    "print(refreshed_docs)\n",
    "print(\"Num of inserted/refreshed documents : \", sum(refreshed_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 True로 나왔으니 인덱스를 다시 업데이트 해야 함.\n",
    "index = VectorStoreIndex.from_documents(docs)\n",
    "index.storage_context.persist(persist_dir='./storage/cache/papers/llama2_node_id/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "Num of inserted/refreshed documents :  0\n"
     ]
    }
   ],
   "source": [
    "docs = SimpleDirectoryReader(\"./assets\", filename_as_id=True).load_data()\n",
    "refreshed_docs = index.refresh_ref_docs(documents=docs, update_kwargs={\"delete_kwargs\":{\"delete_from_docstore\":True}})\n",
    "print(refreshed_docs)\n",
    "print(\"Num of inserted/refreshed documents : \", sum(refreshed_docs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('llamaindex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f13b51dec9893a665284acd155bab776a7e14c668dd25de27de89f99a4571a06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
