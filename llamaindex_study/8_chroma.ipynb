{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader('./assets/', filename_as_id=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_clint = chromadb.EphemeralClient()\n",
    "chroma_collection = chroma_clint.create_collection(\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.storage.storage_context import StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = chromadb.PersistentClient(path='./storage/chroma')\n",
    "chroma_collection =db.get_or_create_collection(\"llama2\")\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['a18cb57d-4d5e-499f-b109-6db32bf97675', '68a3be7b-8fa0-4a8c-9aef-f881f4c94981']], 'distances': [[0.2875857353210449, 0.289158707777537]], 'metadatas': [[{'_node_content': '{\"id_\": \"a18cb57d-4d5e-499f-b109-6db32bf97675\", \"embedding\": null, \"metadata\": {\"page_label\": \"1\", \"file_name\": \"llama2.pdf\", \"file_path\": \"assets/llama2.pdf\", \"file_type\": \"application/pdf\", \"file_size\": 13661300, \"creation_date\": \"2024-02-05\", \"last_modified_date\": \"2023-12-16\", \"last_accessed_date\": \"2024-02-05\"}, \"excluded_embed_metadata_keys\": [\"file_name\", \"file_type\", \"file_size\", \"creation_date\", \"last_modified_date\", \"last_accessed_date\"], \"excluded_llm_metadata_keys\": [\"file_name\", \"file_type\", \"file_size\", \"creation_date\", \"last_modified_date\", \"last_accessed_date\"], \"relationships\": {\"1\": {\"node_id\": \"assets/llama2.pdf_part_0\", \"node_type\": \"4\", \"metadata\": {\"page_label\": \"1\", \"file_name\": \"llama2.pdf\", \"file_path\": \"assets/llama2.pdf\", \"file_type\": \"application/pdf\", \"file_size\": 13661300, \"creation_date\": \"2024-02-05\", \"last_modified_date\": \"2023-12-16\", \"last_accessed_date\": \"2024-02-05\"}, \"hash\": \"35f986cb324ca6f112ceec6cd621884fa8214186fd7774da74e3905a48f859ad\", \"class_name\": \"RelatedNodeInfo\"}, \"2\": {\"node_id\": \"0dee78d9-7b5e-4de9-89b3-f8b54146cab9\", \"node_type\": \"1\", \"metadata\": {\"page_label\": \"26\", \"file_name\": \"2312.02783.pdf\", \"file_path\": \"assets/2312.02783.pdf\", \"file_type\": \"application/pdf\", \"file_size\": 1719264, \"creation_date\": \"2024-02-05\", \"last_modified_date\": \"2024-02-03\", \"last_accessed_date\": \"2024-02-05\"}, \"hash\": \"ab3d02caf9b6508949075c3d035f9747ab97334bcbb0126bf526b666c921747b\", \"class_name\": \"RelatedNodeInfo\"}, \"3\": {\"node_id\": \"809436c8-f3e9-49bf-8ede-7619ff5ea65f\", \"node_type\": \"1\", \"metadata\": {}, \"hash\": \"2943feba461bcc0a8827ff332f9eb64520303e271d9b6aa7269e9231d281aac6\", \"class_name\": \"RelatedNodeInfo\"}}, \"text\": \"\", \"start_char_idx\": 0, \"end_char_idx\": 1880, \"text_template\": \"{metadata_str}\\\\n\\\\n{content}\", \"metadata_template\": \"{key}: {value}\", \"metadata_seperator\": \"\\\\n\", \"class_name\": \"TextNode\"}', '_node_type': 'TextNode', 'creation_date': '2024-02-05', 'doc_id': 'assets/llama2.pdf_part_0', 'document_id': 'assets/llama2.pdf_part_0', 'file_name': 'llama2.pdf', 'file_path': 'assets/llama2.pdf', 'file_size': 13661300, 'file_type': 'application/pdf', 'last_accessed_date': '2024-02-05', 'last_modified_date': '2023-12-16', 'page_label': '1', 'ref_doc_id': 'assets/llama2.pdf_part_0'}, {'_node_content': '{\"id_\": \"68a3be7b-8fa0-4a8c-9aef-f881f4c94981\", \"embedding\": null, \"metadata\": {\"page_label\": \"36\", \"file_name\": \"llama2.pdf\", \"file_path\": \"assets/llama2.pdf\", \"file_type\": \"application/pdf\", \"file_size\": 13661300, \"creation_date\": \"2024-02-05\", \"last_modified_date\": \"2023-12-16\", \"last_accessed_date\": \"2024-02-05\"}, \"excluded_embed_metadata_keys\": [\"file_name\", \"file_type\", \"file_size\", \"creation_date\", \"last_modified_date\", \"last_accessed_date\"], \"excluded_llm_metadata_keys\": [\"file_name\", \"file_type\", \"file_size\", \"creation_date\", \"last_modified_date\", \"last_accessed_date\"], \"relationships\": {\"1\": {\"node_id\": \"assets/llama2.pdf_part_35\", \"node_type\": \"4\", \"metadata\": {\"page_label\": \"36\", \"file_name\": \"llama2.pdf\", \"file_path\": \"assets/llama2.pdf\", \"file_type\": \"application/pdf\", \"file_size\": 13661300, \"creation_date\": \"2024-02-05\", \"last_modified_date\": \"2023-12-16\", \"last_accessed_date\": \"2024-02-05\"}, \"hash\": \"35f08b256954db892f24b57495eb9c1013f83fca88d6bd50c0b8e460f11caa06\", \"class_name\": \"RelatedNodeInfo\"}, \"2\": {\"node_id\": \"4df70aa8-b5fd-40bc-920a-116371f7c1f8\", \"node_type\": \"1\", \"metadata\": {\"page_label\": \"36\", \"file_name\": \"llama2.pdf\", \"file_path\": \"assets/llama2.pdf\", \"file_type\": \"application/pdf\", \"file_size\": 13661300, \"creation_date\": \"2024-02-05\", \"last_modified_date\": \"2023-12-16\", \"last_accessed_date\": \"2024-02-05\"}, \"hash\": \"85f719aa8a7f6ed5e62236372d704b85ebf8568d95c17fe5b090b11331e4ef2a\", \"class_name\": \"RelatedNodeInfo\"}, \"3\": {\"node_id\": \"0de69131-4374-4f0f-914e-770b6d065e34\", \"node_type\": \"1\", \"metadata\": {}, \"hash\": \"2ceac0d433db98ab106ff338ec2d1e2c71f2bd5ba931567ad904ba98d73d1c1e\", \"class_name\": \"RelatedNodeInfo\"}}, \"text\": \"\", \"start_char_idx\": 2918, \"end_char_idx\": 4837, \"text_template\": \"{metadata_str}\\\\n\\\\n{content}\", \"metadata_template\": \"{key}: {value}\", \"metadata_seperator\": \"\\\\n\", \"class_name\": \"TextNode\"}', '_node_type': 'TextNode', 'creation_date': '2024-02-05', 'doc_id': 'assets/llama2.pdf_part_35', 'document_id': 'assets/llama2.pdf_part_35', 'file_name': 'llama2.pdf', 'file_path': 'assets/llama2.pdf', 'file_size': 13661300, 'file_type': 'application/pdf', 'last_accessed_date': '2024-02-05', 'last_modified_date': '2023-12-16', 'page_label': '36', 'ref_doc_id': 'assets/llama2.pdf_part_35'}]], 'embeddings': None, 'documents': [['Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023', '(2021)alsoilluminatesthedifficultiestiedtochatbot-oriented\\nLLMs, with concerns ranging from privacy to misleading expertise claims. Deng et al. (2023) proposes\\na taxonomic framework to tackle these issues, and Bergman et al. (2022) delves into the balance between\\npotential positive and negative impacts from releasing dialogue models.\\nInvestigationsintoredteamingrevealspecificchallengesintunedLLMs,withstudiesbyGangulietal.(2022)\\nand Zhuoet al. (2023) showcasing a variety ofsuccessful attack typesand their effects onthe generation of\\nharmful content. National security agencies and various researchers, such as (Mialon et al., 2023), have also\\nraisedredflagsaroundadvancedemergentmodelbehaviors,cyberthreats,andpotentialmisuseinareaslike\\nbiological warfare. Lastly, broader societal issues like job displacement due to accelerated AI research and an\\nover-reliance on LLMs leading to training data degradation are also pertinent considerations (Acemoglu\\nandRestrepo,2018;AutorandSalomons,2018;Webb,2019;Shumailovetal.,2023). Wearecommittedto\\ncontinuing our work engaging with the broader policy, academic, and industry community on these issues.\\n7 Conclusion\\nInthisstudy,wehaveintroduced Llama 2,anewfamilyofpretrainedandfine-tunedmodelswithscales\\nof7billionto70billionparameters. Thesemodelshavedemonstratedtheircompetitivenesswithexisting\\nopen-source chat models, as well as competency that is equivalent to some proprietary models on evaluation\\nsetsweexamined,althoughtheystilllagbehindothermodelslikeGPT-4. Wemeticulouslyelaboratedonthe\\nmethodsandtechniquesappliedinachievingourmodels,withaheavyemphasisontheiralignmentwiththe\\nprinciplesofhelpfulnessandsafety. Tocontributemoresignificantlytosocietyandfosterthepaceofresearch,\\nwehaveresponsiblyopenedaccessto Llama 2 andLlama 2-Chat . Aspartofourongoingcommitmentto\\ntransparency and safety, we plan to make further improvements to Llama 2-Chat in future work.\\n36']], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "\n",
    "# chroma collection 기본 사용법\n",
    "embed_model = OpenAIEmbedding()\n",
    "search_text = \"llama2\"\n",
    "embedding = embed_model.get_text_embedding(search_text)\n",
    "\n",
    "# chroma collection에서 검색할 수 있음. 2개의 결과를 찾음\n",
    "results = chroma_collection.query(\n",
    "    query_embeddings = [embedding],\n",
    "    n_results = 2\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 is a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. These models, specifically the Llama 2-Chat models, are optimized for dialogue use cases and have demonstrated competitiveness with existing open-source chat models. The developers of Llama 2 have provided a detailed description of their approach to fine-tuning and safety improvements, with the aim of enabling the community to build on their work and contribute to the responsible development of LLMs.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query('What is llama2?')\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('llamaindex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f13b51dec9893a665284acd155bab776a7e14c668dd25de27de89f99a4571a06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
