# Abstract

대규모 언어 모델(Large Language Models, LLMs)은 자연어 처리 분야에서 강력한 도구로써 최근 추천 시스템 분야에서도 큰 관심을 받고 있습니다. 이러한 모델들은 많은 데이터를 활용하여 학습하며, 추천 시스템을 개선하기 위해 효과적인 방법들을 제공합니다. 이 연구는 LLM 기반 추천 시스템을 종합적으로 살펴보고, 이를 두 가지 주요 유형으로 분류하고 분석합니다. 이를 통해 연구자와 실무자들에게 유용한 통찰력을 제공하고, LLM 기반 추천에 관한 관련 논문을 인덱싱하기 위한 GitHub 저장소를 생성했습니다.

# 1. Introduction

추천 시스템은 사용자가 원하는 항목이나 콘텐츠를 찾는 데 중요한 역할을 합니다. 최근에는 대규모 언어 모델(Large Language Models, LLMs)을 활용하여 추천 시스템을 개선하는 연구가 늘어나고 있습니다.

- 기존의 추천 시스템과 다르게, LLM 기반 모델은 문맥 정보를 포착하고 사용자 쿼리, 항목 설명 및 기타 텍스트 데이터를 효과적으로 이해합니다.
- 데이터 희소성 문제에서, LLM은 Zero/Few shot 추천 능력을 통해 추천 시스템에 새로운 가능성을 제공합니다.
- 이 모델들은 사실적인 정보, 도메인 전문지식 및 상식적 추론과 같은 폭넓은 사전 훈련을 통해 미리 지정된 항목이나 사용자에 대한 사전 노출 없이도 합리적인 추천을 제공할 수 있습니다.
- 개인화된 추천을 제공할 수 있어 사용자 만족도를 높일 수 있음
- 이러한 연구 방향은 `데이터 희소성과 효율성 문제를 해결`하며, 추천 시스템 분야에 새로운 가능성을 제시.

# 2. Modeling Paradigms and Taxonomy

- 대규모 언어 모델(Large Language Models, LLMs)의 기본 구조는 여러 개의 트랜스포머 블록으로 이루어져 있으며, GPT, PaLM, LLaMA 등이 있음
- 이 아키텍처의 입력은 일반적으로 토큰 임베딩, 위치 임베딩 등으로 구성되며, 예상 출력은 출력 모듈에서 얻을 수 있습니다.
- 이 과정에서 입력과 출력은 모두 텍스트 시퀀스입니다. 이 논문에서는 언어 모델을 추천 시스템에 적용하는 모델링 패러다임을 세 가지 범주로 나눕니다:

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/19fd67b1-0aa7-45f9-9b6d-a8b441f60733/6fe08b8b-55e5-49e7-b2fb-1d751dc40d6b/Untitled.png)

- LLM 임베딩 + RS : 언어 모델을 특징 추출기로 사용하여 항목과 사용자의 특성을 추출하고 해당 `특성을 임베딩으로 출력`합니다.
- LLM 토큰 + RS : 입력된 `항목과 사용자의 특성을 기반으로 토큰을 생성`하고, 이를 통해 추천 시스템의 의사 결정에 활용합니다.
- LLM으로서의 RS : 사전 훈련된 LLM을 직접 강력한 추천 시스템으로 사용합니다. 입력 시퀀스에는 프로파일 설명, 행동 프롬프트 및 작업 지침이 포함되며, 출력 시퀀스는 합리적인 추천 결과를 제공합니다.

- `판별형 LLM과 생성형 LLM 두 주요 범주로 나누어 분류됨`. 판별형 언어 모델은 임베딩에 적합하고, 생성형 언어 모델은 응답 생성 능력을 통해 다양한 패러다임을 지원.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/19fd67b1-0aa7-45f9-9b6d-a8b441f60733/08d2a395-629d-476a-b03c-1c7355b2cd0a/Untitled.png)

# 3. Discriminative LLMs for Recommendation

- 추천 분야에서 말하는 판별형 언어 모델은 주로 BERT 시리즈 [Devlin et al., 2019]와 같은 모델.
- 판별형 언어 모델은 자연어 이해 작업에서의 전문성 때문에 종종 하위 작업의 임베딩 기반으로 간주됩니다. 이는 추천 시스템에도 해당됩니다. 대부분의 기존 연구는 사전 훈련된 BERT와 같은 모델의 표현을 fine-tuning을 통해 도메인 특정 데이터와 일치시킵니다. 또한, 일부 연구에서는 프롬프트 튜닝과 같은 훈련 전략을 탐구하기도 합니다.

## 3.1 Fine - Tuning

- 대부분의 BERT 기반 추천 방법은 이 전략을 사용.
- 다양한 추천 작업에서 효과적인 모델을 개발하기 위해 BERT와 같은 언어 모델을 Fine-tuning하여 사용자 표현을 학습하거나 제품 랭킹을 향상시키는 등의 결과를 얻음.
- 그룹 추천, 검색/매칭, CTR 예측과 같은 다양한 작업 및 시나리오에서도 Fine-tuning 전략을 적용한 연구가 이루어짐.

## 3.2 Prompt Tuning

- 프롬프트 튜닝은 LLMs를 다양한 추천 작업에 맞게 조정하는 대신, 사전 훈련된 손실과 조화를 이루도록 시도하는 방법.
- 이를 위해 하드/소프트 프롬프트와 `label word verbalizer`를 사용하며, 예를 들어 BERT를 활용하여 추천 작업에 Fine-tuning 없이도 관련 항목을 우선적으로 처리할 수 있다는 연구 결과가 있습니다.
- 또한 프롬프트를 사용한 대화형 추천 시스템과 뉴스 추천에 프롬프트 학습 패러다임을 적용하여 추천 시스템의 성능을 현격하게 향상시키는 효과가 확인되었습니다.
- Yang et al. (2021)는 프롬프트를 사용한 대화형 추천 시스템을 개발하여 `BERT 기반의 항목 인코더가 각 항목의 메타데이터를 직접 임베딩으로 매핑하도록` 함.
- 최근 Prompt4NR [Zhang and Wang, 2023]는 뉴스 추천을 위한 프롬프트 학습 패러다임을 개척했습니다.

# 4. Generative LLMs for Recommendation

- 판별 모델 기반 접근 방식은 LLMs가 학습한 표현을 추천 도메인에 적용
- 생성 모델 기반 작업은 추천 작업을 자연어 작업으로 변환한 다음, In Context Learning, Promt Tuning, Instruction Tuning 같은 기술을 사용하여 LLMs를 직접적으로 추천 결과를 생성하도록 조정.
- 이러한 생성 모델 접근 방식은 튜닝 여부에 따라 두 가지 패러다임으로 나눌 수 있음.

## 4.1 Non-tuning Paradigm

- LLMs는 많은 이전에 보지 못한 작업에서 강력한 Zero/Few-Shot 능력이 있음 [Brown et al., 2020; Ouyang et al., 2022].
- 따라서, 최근의 몇몇 연구는 `LLMs가 이미 추천 능력을 가지고 있다고 가정`하고 이 능력을 `특정 프롬프트를 도입하여 활성화`하려고 시도.
- 모델 매개변수를 조정하지 않고 LLMs를 추천 작업에 적용하기 위해 Instruction 및 In-Context Learning의 최근 실천 방법을 사용 [Brown et al., 2020].

### Prompting

- Liu et al.(2023a)은 ChatGPT의 성능을 5가지 일반적인 추천 작업, 즉 평점 예측, 시퀀스 추천, 직접 추천, 설명 생성, 리뷰 요약에 대해 체계적으로 평가.
- 일반적인 추천 프롬프트 구성 프레임워크를 제안했습니다. 이 프레임워크는 다음과 같이 구성됩니다.
    1. task description **:** 추천 작업을 자연어 처리 작업에 맞게 조정.
    2. behavior injection **:** 사용자-항목 상호 작용을 통합하여 LLM이 사용자 선호도와 필요를 파악.
    3. format indicator **:** 출력 형식을 제한하고 추천 결과를 더 이해하고 평가.
- Dai et al.(2023)은 ChatGPT의 추천 능력을 점수 기반, 쌍 기반, 목록 기반 랭킹을 포함하는 세 가지 일반적인 정보 검색 작업에 대해 경험적 분석을 수행.
- 각 작업 유형에 따라 다른 프롬프트를 제안하고 `프롬프트 시작 부분에 역할 지시(예: 지금 뉴스 추천 시스템입니다.)를 도입`하여 ChatGPT의 도메인 적응 능력을 향상시켰습니다.

- 서로 다른 프롬프트 입력의 향상을 평가하기 위해 Sanner et al.(2023)은 실험에서 항목만(항목 속성), 언어만(사용자 선호도 설명), 결합된 언어+항목의 `세 가지 프롬프트 템플릿을 설계`.
- 언어 모델의 성능을 분석한 결과, `Zero-Shot, Few-Shot 전략은 항목 선호도를 고려하지 않고 언어 기반 선호도만 기반으로 추천을 만드는 데 매우 효과적`이라는 것을 발견했습니다.
- 실제로, 이러한 전략은 특히 `Cold Start 시나리오에서 아이템 기반 협업 필터링 방법과 비교할 때 경쟁력이 매우 뛰어나다는 것이 입증됨`.
- MINT [Mysore et al., 2023]는 사용자의 상호 작용 데이터를 기반으로 프롬프트를 통해 사용자의 의도를 요약하기 위해 175B 매개변수 LLM인 InstructGPT를 사용하여 합성 내러티브 쿼리를 생성했습니다. 이 쿼리는 더 작은 언어 모델을 사용하여 필터링되었고, 검색 모델은 합성 쿼리와 사용자 항목 모두에서 훈련되었습니다. 결과는 이 모델들이 몇몇 강력한 기본 모델과 삭제된 모델을 능가한다는 것을 보여줍니다.
- 1-샷 설정에서 이 모델들은 내러티브 기반 추천에 직접 사용된 175B LLM과 일치하거나 더 뛰어난 성능을 보였습니다. 하지만 이 방법들은 텍스트 설명에서 주제를 분해하는 것을 고려하지 않았기 때문에 노이즈가 많고 목표가 불분명한 프롬프트가 생성될 수 있습니다.
- KAR [Xi et al., 2023]은 `사용자 선호도와 사실적 지식에 대한 정확한 추론을 유도하기 위해 factorization prompting을 도입하여 이 문제를 해결`했습니다.

일부 연구에서는 일반적인 프레임워크를 제안하는 대신 특정 추천 작업에 효과적인 프롬프트 설계에 중점을 둡니다.

- *Sileo et al.(2022)**은 GPT-2의 사전 훈련 코퍼스에서 영화 추천 프롬프트를 마이닝했습니다.
- *Hou et al.(2023)**은 LLM의 시퀀스 추천 능력을 향상시키기 위한 두 가지 프롬프트 방법을 소개했습니다:
    - 최근 이력 중점 시퀀스 프롬프트: 사용자 상호 작용 기록의 시퀀스 정보를 인식할 수 있도록 합니다.
    - 부트스트래핑: 후보 항목 목록을 여러 번 셔플하고 순위에 대한 평균 점수를 사용하여 위치 편향 문제를 완화합니다.
- *Sun et al.(2023)**은 LLM의 입력 토큰 수 제한으로 인해 긴 후보 목록을 프롬프트에 입력하기 어렵다는 문제를 해결하기 위해 슬라이딩 윈도우 프롬프트 전략을 제안했습니다. 이 전략은 매번 윈도우 내의 후보만 순위를 매기고 윈도우를 뒤에서 앞으로 순서로 슬라이딩한 다음 이 프로세스를 여러 번 반복하여 전체 순위 결과를 얻습니다.

LLM을 추천 시스템으로 활용하는 것 외에도 일부 연구에서는 LLM을 사용하여 모델 특징을 구성합니다.

- *GENRE [Liu et al., 2023c]**는 LLM을 활용하여 뉴스 추천을 위한 세 가지 특징 향상 하위 작업을 수행하는 세 가지 프롬프트를 소개했습니다. 구체적으로, ChatGPT를 사용하여 요약에 따라 뉴스 제목을 다듬고, 사용자 읽기 기록에서 프로필 키워드를 추출하고, 합성 뉴스를 생성하여 사용자 기록 상호 작용을 풍부하게 했습니다. LLM이 구성한 이러한 특징을 통합하여 기존 뉴스 추천 모델을 크게 개선할 수 있습니다.
- *NIR [Wang and Lim, 2023]**은 사용자 선호도 키워드를 생성하고 사용자 상호 작용 기록에서 대표적인 영화를 추출하여 영화 추천을 개선하기 위한 두 가지 프롬프트를 설계했습니다.

현실적인 추천 시스템은 순위 모델 외에도 콘텐츠 데이터베이스, 후보 검색 모델 등 여러 중요한 구성 요소로 구성됩니다. 이에 따라 LLM 활용 방법 중 하나는 전체 시스템 제어기로 활용하는 것입니다.

- **ChatREC [Gao et al., 2023]:** 다중 회복 대화를 통해 사용자 요구 사항을 이해하고 기존 추천 시스템을 호출하여 결과를 제공하는 대화형 추천 프레임워크를 설계했습니다. 또한 ChatGPT는 데이터베이스를 제어하여 프롬프트를 보완하고 차가운 시작 항목 문제를 해결하기 위해 관련 콘텐츠를 검색할 수 있습니다.
- **GeneRec [Wang et al., 2023b]:** 생성적 추천 프레임워크를 제안하고 LLM을 사용하여 기존 항목을 추천할지 아니면 AIGC 모델을 통해 새로운 항목을 생성할지를 제어했습니다.
- **RecAgent [Wang et al., 2023a]:** LLM을 지능형 시뮬레이터로 활용하여 가상 추천 환경을 개발했습니다. 이 시뮬레이터는 사용자 모듈과 추천자 모듈로 구성되어 사용자는 추천 사이트 탐색, 다른 사용자와의 상호 작용, 소셜 미디어 게시물 작성 등을 할 수 있으며, 추천자 모듈은 맞춤 검색 및 추천 목록을 제공합니다. 시뮬레이터 내 사용자는 LLM을 기반으로 행동하며 실제 상황을 반영하는 방식으로 유기적으로 발전할 수 있습니다. 이 프로젝트는 RL 기반 추천에 대한 피드백 시뮬레이션, 소셜 미디어 사용자 간 정보 전파 과정 추적 등 다양한 응용 분야에서 활용 가능성을 보여줍니다.

결론적으로, 이 연구들은 자연어 프롬프트를 활용하여 LLM의 제로샷 능력을 추천 작업에 활성화하여 저렴하고 실용적인 솔루션을 제공합니다.

### In-context Learning

- GPT-3와 같은 LLM은 몇 가지 데모 `입력-레이블 쌍만으로 새로운 작업과 정보에 빠르게 적응`할 수 있음.
- Hou et al. (2023)은 시퀀스 추천을 위해 입력 상호 작용 시퀀스 자체를 강화하여 demonstration example를 도입했습니다.
- Liu et al. (2023a)과 Dai et al. (2023)은 다양한 추천 작업에 대한 demonstration example 템플릿을 설계했으며 실험 결과 컨텍스트 학습 방법이 대부분 작업에서 LLM의 추천 능력을 향상시켰음.
- 적합한 demonstration example는 LLM의 출력 형식과 내용을 제어하여 일반적인 평가 지표를 향상시킬 수 있습니다.
- 하지만 프롬프트와 비교하여 컨텍스트 학습을 추천 작업에 활용한 연구는 아직 많지 않습니다. demonstration example 선택과 데모 예시 수가 추천 성능에 미치는 영향 등 많은 미해결 문제가 남아 있습니다.

## 4.2 **Tuning Paradigm**

- 적절한 프롬프트 설계를 통해 추천 성능을 증가시킬 수 있지만, `이런 방식으로 구축된 추천 시스템은 특정 데이터에 대해 특정 작업을 위해 훈련된 추천 모델의 성능을 능가하지 못함.`
- 따라서 많은 연구자들은 추가적인 파인튜닝 또는 프롬프트 학습을 통해 LLM의 추천 능력을 향상시키는 것을 목표로 함.
- 구체적으로 파인튜닝 패러다임에서 차별적 및 생성적 대형 언어 모델의 사용 방법은 매우 유사합니다. LLM은 주로 사용자 또는 항목의 표현을 추출하는 인코더 역할을 하며, LLM의 매개변수는 이후 하위 추천 작업의 특정 손실 함수에서 미세 조정됩니다.
- 한편 프롬프트 튜닝 및 지시 튜닝 패러다임에서는 대형 모델의 출력은 항상 텍스트이며, 매개변수는 언어 모델링 손실을 사용하여 훈련됩니다.
- `Prompt Tuning은 주로 평점 예측과 같은 특정 작업에 중점을 두는 반면, Instruction Tuning은 LLM이 다양한 유형의 지시를 가진 여러 작업을 위해 훈련됨.`
- 따라서 지시 튜닝을 통해 LLM은 더 나은 제로샷 능력을 얻을 수 있습니다.

### Fine-Tuning

파인튜닝 패러다임에서는 생성적 LLM의 활용 및 훈련 방법이 3.1절에서 논의한 판별적 LLM과 근본적으로 유사하기 때문에 이 하위 절에서는 몇 가지 대표적인 연구만 소개하겠습니다.

- Petrov and Macdonald (2023)**은 `GPT-2 기반 생성 시퀀스 추천 모델인 GPTRec`을 제안했습니다.
    - 판별적 LLM 기반인 BERT4Rec과 달리 GPTRec은 생성적 LLM을 사용하고 메모리 효율성을 위해 SVD 토큰화를 사용하며 Next-K 생성 전략을 사용.
- Kang et al. (2023)은 `사용자 히스토리 상호 작용을 프롬프트 형식으로 만들 것을 제안`.
    - 여기서 각 상호 작용은 아이템에 대한 정보로 표현되며, 평점 예측 작업을 다중 클래스 분류 및 회귀라는 두 가지 다른 작업으로 공식화했습니다.
- Li et al. (2023c)은 1750억 개의 파라미터를 가진 GPT-3와 같은 `LLM이 텍스트 기반 협업 필터링(TCF)에 미치는 영향을 연구`했습니다.
    - Li et al.은 `더 강력한 LLM을 텍스트 인코더로 사용하면 추천 정확도가 높아질 수 있음을 발견`.
    - 하지만 매우 큰 LM은 사용자와 아이템의 보편적인 표현을 만들지 못할 수 있으며, 간단한 ID 기반 협업 필터링은 여전히 Warm Item 추천 설정에서 경쟁력이 높은 접근 방식으로 남아 있습니다.

### Prompt Tuning

프롬프트 튜닝 패러다임에서는 `LLM이 일반적으로 사용자/아이템 정보를 입력으로 받아 사용자 선호도(예: 좋아요/싫어요, 평점) 또는 사용자가 관심을 가질 만한 아이템을 출력`합니다.

- Bao et al. (2023)은 TALLRec이라는 모델을 제안했습니다.
    - TALLRec은 두 가지 튜닝 단계를 거쳐 훈련됩니다. 구체적으로, TALLRec은 먼저 Alpaca [Taori et al., 2023]의 자기 지시 데이터를 기반으로 미세 조정됩니다.
    - 그런 다음 TALLRec은 사용자의 과거 시퀀스가 입력이고 "예" 또는 "아니오" 피드백이 출력인 추천 튜닝을 통해 추가적으로 미세 조정됩니다.
- Ji et al. (2023)은 GenRec이라는 LLM 기반 생성 추천 방법을 제시했습니다.
    - GenRec은 생성적 LLM의 생성 능력을 활용하여 직접 추천할 대상 아이템을 생성합니다. 구체적으로 Ji et al.은 입력 생성 함수를 사용하여 `아이템을 프롬프트로 변환하고 LLM을 사용하여 다음 아이템을 생성하도록 제안`.
- Chen (2023)은 LLM의 잠재력을 추천에 활용하기 위한 다단계 접근 방식을 제안했습니다.
    - Chen은 먼저 LLM을 사용하여 사용자 선호도 요약을 생성하도록 제안. 예를 들어, 사용자의 음악 및 TV 시청 기록을 분석하여 LLM은 "팝 음악" 및 "판타지 영화"와 같은 요약을 생성할 수 있습니다.
    - 그런 다음 검색 모듈을 사용하여 훨씬 작은 후보 풀을 얻습니다. 마지막으로, 상호 작용 기록, 자연어 사용자 프로필 및 검색된 후보를 사용하여 LLM에 입력할 수 있는 자연어 프롬프트를 구성합니다.

위에 언급된 방법들은 대형 언어 모델을 사용하여 일반적인 작업에 대한 추천을 하는 것입니다. 하지만 앞서 언급했듯이 대형 언어 모델의 중요한 장점은 모델 매개변수를 특정 도메인과 효율적으로 맞출 수 있다는 것입니다. 현재 이 점을 가장 광범위하게 활용한 도메인은 온라인 채용 시나리오입니다.

- 구체적으로, 채용-이력서 매칭 영역에서 생성 추천 모델 GIRL [Zheng et al., 2023]은 LLM을 사용하여 잠재적인 직무 설명(JD)을 생성하여 추천 설명성과 적절성을 높였습니다. GLRec [Wu et al., 2023]은 LLM 추천 시스템이 행동 그래프를 해석하는 데 사용할 수 있는 새로운 접근 방식인 메타 경로 프롬프트 생성기를 도입했습니다. 이 방법은 또한 프롬프트 편향을 완화하기 위해 경로 증강 모듈을 통합했습니다.
- 이후 LLM 기반 프레임워크가 `생성적 적대 신경망(GAN)을 사용하여 낮은 품질의 이력서를 고품질 생성된 이력서와 일치시키는 것이 도입`되었습니다. 이 정렬 과정은 이력서 표현을 개선하여 추천 결과를 향상시켰습니다 [Du et al., 2023].

온라인 채용 분야 외에도 대형 언어 모델의 강력한 생성 능력을 활용하여 특정 작업을 수행하는 다양한 연구가 진행

- **제품 추천:** Jin et al. (2023)은 사용자에게 다음 관심 상품 제목을 생성하기 위해 LLM을 사용했습니다. 그들은 데이터셋에서 정의된 생성 목적을 사용하여 mT5 모델을 미세 조정했습니다. 하지만 마지막 상품 제목을 결과로 사용하는 간단한 휴리스틱 방법이 미세 조정된 언어 모델의 성능을 능가했습니다.
- **대화적 추천:** Friedman et al. (2023)은 LLM을 사용하여 사용자와 대화하는 대화 관리 모듈, LLM을 사용하여 사용자 선호도와 일치하는 아이템을 선택하는 랭커 모듈, 시스템 모듈 조정을 위한 합성 대화를 생성하는 제어 가능한 LLM 기반 사용자 시뮬레이터로 구성된 RecLLM을 제안했습니다.
- **뉴스 추천:** Li et al. (2023e)은 사용자 행동과 뉴스를 텍스트 형식으로 설명할 수 있는 PBNR을 제안했습니다. 구체적으로, 관련 필드를 원시 데이터의 해당 정보로 대체하는 입력-목표 템플릿을 설계하여 개인화된 프롬프트를 생성합니다. PBNR은 훈련 전체에서 랭킹 손실과 언어 생성 손실을 통합하여 추천 작업에서 LLM의 성능을 향상시킵니다.
- **검색 기반 추천:** Li et al. (2023a)은 추천 작업을 쿼리 생성 + 검색 문제로 간주했습니다. 또한 LLM을 사용하여 다양하고 해석 가능한 사용자 관심 표현(즉, 쿼리)을 생성했습니다.
- **프롬프트 학습:** LLM을 직접 미세 조정하는 것 외에도 일부 연구에서는 프롬프트 학습을 활용하여 성능 향상을 달성하려고 합니다. 예를 들어, Wang et al. (2022)은 지식 강화 프롬프트 학습을 기반으로 하는 통합 대화 추천 시스템 UniCRS를 설계했습니다. 이 논문에서는 LLM의 매개변수를 고정하고 프롬프트 학습을 통해 응답 생성 및 아이템 추천을 위한 소프트 프롬프트를 훈련했습니다. Li et al. (2023b)은 LLM의 생성 능력을 기반으로 사용자가 이해할 수 있는 설명을 제공했습니다. 이는 이산 프롬프트 학습과 연속 프롬프트 학습을 모두 시도했으며, 순차적 조정과 추천을 정규화로 사용하는 두 가지 훈련 전략을 제안했습니다.

이처럼 LLM은 다양한 추천 시나리오에 활용 가능성을 보여주고 있으며, 앞으로도 지속적인 연구 개발을 통해 그 활용 범위와 성능이 더욱 발전할 것으로 기대됩니다.

### Instruction Tuning

- LLM이 `여러 가지 유형의 instuction이 포함된 다양한 작업에 대해 미세 조정`됩니다. 이를 통해 LLM은 사람의 의도와 더 잘 일치하고 더 우수한 Zero Shot 능력을 달성할 수 있습니다.
- Geng et al. (2022)은 시퀀스 추천, 평점 예측, 설명 생성, 리뷰 요약, 직접 추천 등 다섯 가지 유형의 지시에 대해 T5 모델을 미세 조정하는 것을 제안함. 추천 데이터셋에서 다중 작업 지시 튜닝을 수행한 후, 모델은 보지 못한 개인화된 프롬프트 및 새로운 항목에 대한 제로샷 일반화 기능을 달성함.
- Cui et al. (2022)은 M6 모델을 세 가지 유형의 작업, 즉 채점 작업, 생성 작업 및 검색 작업에 대해 미세 조정하는 것을 제안.
- Zhang et al. (2023b)은 선호, 의도, 작업 형태 등 세 가지 핵심 측면에서 일반적인 지시 형식을 먼저 설계함. 그런 다음 Zhang et al. (2023b)은 `39개의 instruction template을 수동으로 설계`하고 3B FLAN-T5-XL 모델에 대한 지시 튜닝을 위해 사용자 맞춤 지시 데이터를 자동으로 생성.
- 이 접근 방식은 GPT-3.5를 포함한 여러 경쟁 기반 모델보다 우수한 성능을 보였다는 것을 보여주었습니다.

## 5.1 Model Bias

**Position Bias**

- 추천 시스템의 생성 언어 모델링 패러다임에서 사용자 행동 시퀀스와 추천된 후보 등과 같은 다양한 정보는 텍스트 순차적 설명 형식으로 언어 모델에 입력됩니다. 이로 인해 언어 모델 자체에 내재된 위치 편향을 도입할 수 있습니다 [Lu et al., 2021].
- 후보의 순서는 LLM 기반 추천 모델의 순위 결과에 영향을 미치며, 즉 LLM은 종종 상위 순서의 항목을 우선시합니다.
- 또한 모델은 일반적으로 시퀀스의 행동 순서를 잘 포착하지 못합니다. Hou et al. (2022)는 후보의 위치 편향을 완화하고 행동 순서를 향상시키기 위해 무작위 샘플링 기반의 부트스트래핑을 사용하고 최근 상호 작용한 항목을 강조했습니다. 그러나 이러한 해결책들은 충분히 적응력이 없으며, 앞으로 더 견고한 학습 전략이 필요합니다.

**Popularity Bias**

- LLMs의 순위 결과는 `후보 항목의 인기 수준에 영향`을 받습니다. 인기 있는 항목은 종종 LLMs의 사전 훈련 코퍼스에서 널리 논의되고 언급되기 때문에 일반적으로 더 `높은 순위로 평가`됩니다.
- 이 문제를 해결하는 것은 사전 훈련 코퍼스의 구성과 밀접하게 관련되어 있음

**Fairness Bias**

- 사전 훈련된 언어 모델은 민감한 속성과 관련된 `공정성 문제`를 보여준 바 있습니다 [Zhang et al., 2023a]. 이러한 문제들은 훈련 데이터나 특정 작업 주석에 참여한 개인들의 인구 통계에 영향을 받을 수 있습니다 [Ferrara, 2023].
- 이러한 공정성 우려 사항은 `모델이 사용자가 특정 그룹에 속한다고 가정하는 추천`을 하게 할 수 있으며, 상업적으로 적용될 때 논란을 일으킬 수 있는 가능성이 있습니다. `성별이나 인종에 따라 추천 결과에 나타나는 편견`이 있을 수 있음.

## 5.2 Recommendation Prompt Designing

**User/Item Representation**

- 실제로, 추천 시스템은 일반적으로 사용자와 아이템을 나타내기 위해 많은 이산 및 연속적인 특성을 활용합니다. 그러나 대부분의 기존 LLM 기반 연구는 아이템을 나타내기 위해 이름만을 사용하고 사용자를 나타내기 위해 항목 이름 목록을 사용합니다. 이는 사용자와 아이템을 정확하게 모델링하는 데 부족합니다.
- 또한, 사용자의 다양한 행동 시퀀스(예: 클릭, 장바구니 담기, 전자 상거래 도메인에서의 구매)를 선호도 모델링을 위한 자연어로 변환하는 것이 중요합니다. ID와 유사한 특성은 전통적인 추천 모델에서 효과적으로 증명되었지만, 이러한 특성을 프롬프트에 통합하여 개인화된 추천 성능을 향상시키는 것은 도전적입니다.

**Limited Context Length**

- 인풋 컨텍스트 길이 제한은 사용자의 행동 시퀀스의 길이와 후보 항목의 수를 제한하여 최적의 성능이 나오지 않을 수 있음 [Zhang et al., 2023b].
- 기존 연구에서는 사용자 행동 시퀀스에서 대표적인 항목을 선택하는 방법 [Wang and Lim, 2023] 및 후보 목록에 대한 슬라이딩 윈도우 전략과 같은 이 문제를 완화하기 위한 몇 가지 기술을 제안해 왔습니다 [Sun et al., 2023].

## 5.3 Promising Ability

- Zero/Few-Shot 추천 능력. 다양한 추천 작업에서의 실험 결과는 LLMs가 다양한 추천 작업에서 인상적인 제로/퓨-샷 능력을 갖고 있음을 나타냅니다 [Hou et al., 2023; Liu et al., 2023a; Dai et al., 2023].
- 이는 매우 제한된 데이터로 추천 작업을 수행하는 것과 동등한 인-컨텍스트 학습에 해당하는 퓨-샷 학습은 LLMs의 매개 변수를 변경하지 않는다는 것을 가치 있게 언급할 만합니다.
- 이것은 LLMs가 제한된 데이터로 인한 콜드 스타트 문제를 완화하는 잠재력을 갖고 있을 수 있다는 것을 시사합니다.
- 그러나 퓨-샷 학습에 대한 대표적이고 효과적인 데모 예제를 선택하기 위한 더 명확한 안내가 필요하며, 제로/퓨-샷 추천 능력에 대한 결론을 더 지원하기 위해 다양한 도메인에서의 실험 결과가 더 필요한 것과 같은 여전히 열린 질문들이 있습니다.
- 설명 가능한 능력. 생성 모델 LLMs는 자연어 생성에 놀라운 능력을 보입니다. 따라서 LLMs를 사용하여 설명 가능한 추천을 수행하는 것은 자연스러운 아이디어입니다. Liu 등 (2023a)은 설명 생성 작업에서 ChatGPT와 몇 가지 기준 모델 간의 비교 실험을 진행합니다.
- 결과는 미세 조정 없이도 인-컨텍스트 학습 환경에서 ChatGPT가 몇 가지 감독형 전통적인 방법보다 더 좋은 성능을 발휘함을 보여줍니다.
- 또한 인간 평가에 따르면 ChatGPT의 설명은 심지어 기존의 정답보다 더 명확하고 더 합리적으로 여겨집니다. 이러한 흥미로운 초기 실험 결과에 격려를 받아 미세 조정된 LLMs의 성능은 설명 가능한 추천 분야에서 유망할 것으로 기대됩니다.

## 5.4 Evaluation Issues

**Generation Contolling**

- LLMs의 경우 출력은 제공된 지시 형식을 엄격히 준수해야 합니다. 이 지시 형식은 바이너리 응답(예 또는 아니오)을 제공하거나 순위 목록을 생성하는 것과 같습니다. 그러나 실제 응용 프로그램에서 LLMs의 출력은  올바르지 않은 형식으로 응답하거나 답변을 거부할 수 있음 [Dai et al., 2023].
- 생성 모델은 여러 항목을 포함한 순위 매기기 추천 작업을 잘 수행하기 어려움. 이는 그들의 훈련 데이터와 Autoregressive training 때문에 여러 항목을 포함한 순위 문제를 처리하는 데 능력이 떨어지게 됨.
- 현실 시나리오에서 순서를 매기는 데 있어서 여러 항목의 순위를 위한 참 값이 없기 때문에 미세 조정을 통해 해결할 수 없음.
- 순서 기반의 자기회귀적 훈련 논리를 적용하는 것은 어렵습니다. PRP (Pairwise Ranking Prompting) [Qin et al., 2023]은 LLM과 함께 목록 작업을 위한 Pairwise Ranking을 제안하며 모든 쌍을 나열하고 각 항목에 대한 점수를 생성하기 위해 전역 집계를 수행합니다. 그러나 이 논리는 추론 프로세스에서 시간이 많이 걸리는 단점이 존재. 따라서 LLMs의 출력을 더 잘 제어하기 위한 도전에 대처하는 것은 해결해야 할 문제.

**Evaluation Criteria**

- LLMs가 수행하는 작업이 평가 예측 또는 항목 순위와 같은 표준 추천 작업이라면, NDCG, MSE 등의 기존 평가 지표를 사용할 수 있습니다.
- LLMs는 강력한 생성 능력을 가지고 있어 생성적 추천 작업에도 적합합니다 [Wang et al., 2023b]. 생성적 추천 패러다임을 따르면 LLMs는 역사적 데이터에 나타나지 않은 항목을 생성하고 사용자에게 추천할 수 있습니다. 이 경우 LLMs의 생성적 추천 능력을 평가하는 것은 여전히 열린 질문입니다.

**Datasets**

- 현재 이 분야의 대부분의 연구는 주로 MovieLens, Amazon Books 및 유사한 벤치마크 데이터셋과 같은 데이터셋을 사용하여 LLMs의 추천 능력 및 제로/퓨-샷 능력을 테스트합니다.
- 그러나 이로 인해 다음 두 가지 잠재적인 문제가 발생할 수 있습니다. 첫째, 실제 산업용 데이터셋에 비해 이러한 데이터셋은 상대적으로 규모가 작을 수 있으며, LLMs의 추천 능력을 완전히 반영하지 못할 수 있습니다.
- 둘째, 이러한 데이터셋의 항목인 영화 및 책과 같은 항목은 LLMs의 사전 훈련 데이터에 나타난 관련 정보를 가질 수 있습니다. 이로 인해 LLMs의 퓨-샷 학습 능력을 평가할 때 편향을 도입할 수 있습니다. 현재까지는 더 포괄적인 평가를 수행하기 위한 적절한 벤치마크가 부족합니다.

**`대형 언어 모델의 능력과 관련된 몇 가지 한계`**. 

- 모델을 특정 도메인 작업을 위해 훈련하거나 모델 지식을 업데이트할 때 기존 훈련된 지식을 잊어버릴 수 있음[Jang et al., 2022].
- 또 다른 문제는 언어 모델 매개 변수의 다양한 크기에 따라 다른 성능이 발생하는데, 지나치게 큰 모델을 사용하면 추천 시스템의 연구 및 배포에 과도한 계산 비용이 발생할 수 있음 [Hou et al., 2023].

## 6. Conclsion

이 논문에서는 추천 시스템을 위한 대형 언어 모델 (LLMs)의 연구 영역을 검토했습니다. 우리는 기존의 연구를 구별 모델과 생성 모델로 분류하고, 도메인 적응 방식에 따라 자세히 설명

그리고 개념적 혼란을 방지하기 위해 LLM 기반 추천에서의 fine-tuning, prompting, prompt tuning 및 instruction tuning의 정의와 차이점을 제시

우리의 조사는 우리가 알기로는 특히 생성 모델 LLMs를 위한 체계적이고 최신의 검토로, 다양한 관련 연구에서 제시된 공통된 발견과 도전 과제를 더 요약했습니다. 따라서 이 조사는 연구자들에게 LLM 추천에 대한 포괄적인 이해를 얻고 잠재적인 연구 방향을 탐색하는 데 중요한 자원을 제공합니다.

미래를 전망할 때, 계산 능력이 계속 발전하고 인공 지능의 영역이 확대되는 가운데, LLMs를 추천 시스템에서 더 다양한 도메인에서 활용할 수 있는 더 정교한 응용 프로그램이 나타날 것으로 예상됩니다. 또한, 윤리적 고려사항이 더 중요해지면서, 미래의 LLM 기반 추천 시스템은 공정성, 책임성 및 투명성을 보다 본질적으로 통합할 수도 있을 것입니다