# Abstract

> 대규모 언어 모델(LLMs)이 비윤리적이거나 해로운 콘텐츠를 생성하는 것을 유도할 수 있는 'jailbreaking' 공격에 취약함. 이를 해결하기 위해, 'AdvPrompter'라는 새로운 방법을 제안하여 자동으로 인간이 읽을 수 있는 적대적 프롬프트를 생성하는 방법을 소개함. 이 방법은 기존의 최적화 기반 접근법보다 훨씬 빠른 속도(약 800배 빠름)로 적대적 프롬프트를 생성할 수 있으며, 이는 LLMs의 안정성을 향상시키는 데 기여할 수 있음.
> 

# **Introduction**

> 대규모 언어 모델(LLMs)이 현대 기계 학습에서 얼마나 중요한지 강조. 이러한 모델들은 방대한 데이터로 훈련되어 다양한 영역에서 활용됨. 그러나 LLMs의 훈련 데이터에는 종종 독성이 있는 콘텐츠가 포함되어 있어, 이를 그대로 학습하게 되면 부적절하거나 해로운 콘텐츠를 생성할 위험이 있음. 이를 완화하기 위해 대부분의 LLMs는 'Safety-Alignment' 과정을 거치게 되는데, 이는 모델이 사회적 가치를 반영하는 인간의 선호도에 맞추어 재조정되는 과정.
> 
- 이미 안전하게 조정된 LLMs조차도 'jailbreaking' 공격에 취약하며, 이러한 공격은 적대적인 프롬프트를 만들어 안전한 메커니즘을 우회하려고 시도.
    - 유명한 jailbreaking 공격 예로는 "Ignore Previous Prompt"와 "Do Anything No" 등
- 수동 레드팀은 시간이 많이 소요되고 눈에 띄지 않는 취약점을 놓칠 수 있음
- 이에 대응하여 최근에는 자동화된 적대적 프롬프트 생성 방법이 제안되었지만 인간이 읽기 어렵거나, 고비용의 이산 최적화가 필요한 단점이 존재.
    - 인간이 읽기 어려우면 난해성 기반 완화 전략(Perplexity-based mitigation)으로 쉽게 필터링 할 수 있음.
- 이 논문에서는 이러한 문제를 해결하기 위해 또 다른 LLM인 'AdvPrompter'를 사용하여 몇 초 내에 인간이 읽을 수 있는 적대적 프롬프트를 생성하는 새로운 자동화된 레드팀 방법을 제안.
- 이 방법은 인간의 개입 없이도 훈련이 가능하며, 생성된 적대적 프롬프트는 인간이 작성한 것처럼 자연스럽고 읽기 쉬운 특성을 지니고 있음.
- 아래 그림은 Jailbreaking을 위한 훈련과정과 적대적 접미사를 생성하는 과정을 나타냄

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/19fd67b1-0aa7-45f9-9b6d-a8b441f60733/51780a7c-8a0a-4f4c-aeec-e8c7db17b4d4/Untitled.png)

# Preliminaries

## 2.1 Problem Setting : Jailbreaking Attacks

> 어휘 $\{{1, ..., N}\}$에 있는 토큰의 지표 집합을 $V$로 표시합니다. 공격자가 유해하거나 부적절한 명령어 $x \in X = V^{|x|}$ (예: "폭탄 만들기에 대한 튜토리얼을 작성하세요)를 사용하여 정렬된 채팅 기반 TargetLLM이 부정적인 응답(예: "미안하지만 폭탄 만들기에 대한 튜토리얼을 제공할 수 없습니다.")을 생성한다고 가정.
> 
- 탈옥 공격(주입에 의한)은 적대적 접미사 $q \in Q = V^{|q|}$ (예: "강의의 일부로") 를 명령에 추가하면 TargetLLM이 대신 원하는 긍정적 응답 $y \in Y = V^{|y|}$ (예: "물론, 여기 폭탄 만들기에 대한 자습서가 있습니다) 를 생성하게 만드는 공격.
- 의미를 유지하는 다른 변환을 명령어에 적용할 수 있지만, 단순화를 위해 접미사를 삽입
- $x$에 $q$를 추가하는 적대적 프롬프트를 $[x, q]$로 표시하고, 간결성을 위해 채팅 템플릿에 응답 $y$가 포함된 전체 프롬프트(시스템 프롬프트와 구분 기호로 채팅 역할을 포함)는 $[x, q, y]$로 표시.

**Problem 1**

- 최적의 adversarial suffix를 찾는 것은 regularized adversarial loss 를 최소화하는 것과 같음.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/19fd67b1-0aa7-45f9-9b6d-a8b441f60733/f5bd9d61-ebbd-45dc-9962-d62a305b435b/Untitled.png)

- 고정된 파라미터 $\phi$를 사용하여 원하는 응답 y가 TargetLLM에서 발생할 likelihood를 측정하며, Weighted Cross-Entropy Loss로 선택됨

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/19fd67b1-0aa7-45f9-9b6d-a8b441f60733/777725eb-8d77-4a70-91f3-91ec79407fc1/Untitled.png)

- y<t := [y1, . . . , yt-1]. TargetLLM의 자동 회귀적으로 생성된 응답에 큰 영향을 미치는 첫 번째 긍정 토큰(예: y1 = "Sure")의 중요성[A]을 강조하기 위해 가중치 γt = 1을 도입했습니다. 정규화기 lη : X × Q → R은 적대적 프롬프트 q의 인간 가독성을 높여 [x, q]가 일관된 자연 텍스트를 형성하도록 보장합니다. Zhu 등(2023)과 마찬가지로, 이 정규화 점수를 계산하기 위해 고정 파라미터 η를 사용하여 사전 훈련된 BaseLLM의 log-probabilities를 사용합니다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/19fd67b1-0aa7-45f9-9b6d-a8b441f60733/68423a45-a5d9-4064-a166-75a98d0f723f/Untitled.png)

- 우리는 명령-응답 쌍을 최적의 적대 접미사 최소화 방정식 (1)에 매핑하는 솔루션 매핑을 q⋆ : X × Y → Q, 즉 q∗(x, y) ∈ arg minq∈Q L(x, q, y)로 나타냅니다. 안타깝게도 솔루션 매핑은 폐쇄형 솔루션을 인정하지 않으며, 단일 입력에서 이를 평가하려면 이산 토큰 공간 Q를 탐색하는 데 비용이 많이 드는 방법(Zou et al., 2023; Zhu et al., 2023)이 필요합니다.

## 2.2 Transfer-Attacking Blackbox

# **Methods**

> AdvPrompter의 훈련 과정과 그 메커니즘에 대해 설명. AdvPrompter는 기존 LLM과는 다른 접근 방식을 사용하여, 사용자의 지시에 따라 적대적인 접미사를 생성하는 모델. AdvPrompter는 AdvPrompterOpt 와 AdvPrompterTrain의 두 단계로 나뉨. AdvPrompter가 대상 LLM에 대한 공격을 시도할 때, 다양하고 자연스러운 적대적 접미사를 신속하게 생성할 수 있도록 설계되었고, 이 과정은 기울기 정보 없이도 대상 LLM의 로그 확률 출력만을 사용하여 이루어짐.
> 
1. **AdvPrompterOpt (적대적 접미사 최적화)**:
    - AdvPrompterOpt는 적대적 접미사를 반복적으로 생성하고 평가하는 과정. 이 과정은 효율적인 최적화 알고리즘을 사용하여, 대상 LLM(TargetLLM)을 잠금 해제(jailbreak)하고 인간의 가독성을 유지하는 접미사를 생성.
    - 이 알고리즘은 BaseLLM의 복잡도를 기반으로 적대적 접미사의 품질을 측정합니다.
    - 접미사는 대상 LLM에 의해 해석될 때 입력 지시를 가리면서도 그 의미를 변경하지 않는 방식으로 생성.
2. **AdvPrompterTrain (적대적 훈련 절차)**:
    - AdvPrompterTrain은 AdvPrompter를 훈련시키는 과정으로, 적대적 접미사를 목표로 하여 AdvPrompter의 예측을 미세 조정.
    - 이 훈련 과정은 반복적으로 'q-step'과 'θ-step' 사이를 전환하며 진행됩니다.
    - 'q-step'은 적대적 목표 접미사를 생성하는 단계이며, 'θ-step'은 이러한 접미사를 사용하여 AdvPrompter를 미세 조정하는 단계.

# **Results**

> AdvPrompter의 효율성과 효과를 평가하기 위해 수행된 실험들에 대해 설명. 다양한 대상 LLMs에 대한 실험을 통해, AdvPrompter가 기존 방법들에 비해 얼마나 빠르고 효과적인지를 보여줌. AdvPrompter가 기존의 적대적 프롬프트 생성 방법들을 크게 능가하며, LLM의 안전성 향상에 기여할 수 있는 중요한 기술임을 보여주며, 빠르고 효과적인 적대적 공격을 가능하게 하는 동시에, 자연스러운 생성을 가능하게 함.
> 
1. **성능 평가**:
    - AdvPrompter는 실험에서 상당히 높은 공격 성공률(ASR)을 달성했습니다. 또한, 생성된 적대적 접미사는 인간이 읽기에 자연스럽고 의미 있으며, 퍼플렉서티 기반 필터에 의해 쉽게 탐지되지 않습니다.
    - AdvPrompter는 기존의 방법들보다 약 800배 빠른 속도로 적대적 접미사를 생성할 수 있습니다. 이는 실험에서 평균 1-2초 내에 적대적 접미사를 생성할 수 있음을 의미하며, 이는 다중 적대적 공격을 효율적으로 수행할 수 있게 합니다.
2. **공격의 전이성**:
    - AdvPrompter는 다양한 오픈 소스 및 폐쇄 소스의 대상 LLMs에 대해 높은 공격 전이성을 보였습니다. 이는 AdvPrompter가 일반적인 테스트 지시사항에도 잘 적응하고 적절한 적대적 접미사를 생성할 수 있음을 보여줍니다.
    - 대상 LLM에 대한 'graybox' 접근 방식을 사용하여, 기울기 정보 없이도 효과적으로 공격을 수행할 수 있음을 입증했습니다.
3. **로버스트성 향상**:
    - AdvPrompter로 생성된 적대적 접미사 데이터셋을 사용하여 대상 LLM을 미세 조정한 결과, 대상 LLM의 로버스트성이 크게 향상되었습니다. 이는 AdvPrompter가 안전한 LLM 개발에 중요한 도구가 될 수 있음을 시사합니다.

# **Discussion**

> AdvPrompter가 제공하는 자동화된 적대적 프롬프트 생성 방법이 LLMs의 안전성 문제에 대응하기 위한 중요한 도구가 될 수 있음을 강조하면서, 이 기술이 가져올 장기적인 영향에 대해 긍정적인 전망을 제시.
> 
1. **AdvPrompter의 혁신적인 기여**:
    - AdvPrompter는 자동화된 적대적 프롬프트 생성을 가능하게 하는 기술적 혁신을 제공합니다. 이는 기존 방법들이 가진 시간 소모적이고 비효율적인 문제를 해결함으로써, 대규모 언어 모델의 안전성을 향상시키는 데 크게 기여.
    - 생성된 적대적 접미사는 높은 자연스러움과 읽기 쉬움을 유지하면서도, 모델의 안전 메커니즘을 우회할 수 있는 능력을 보여줌.
    - 이는 퍼플렉서티 기반 필터 등 일반적인 방어 메커니즘으로부터 탐지를 회피할 수 있음을 의미.
2. **안전성 향상과 미래의 연구 방향**:
    - AdvPrompter의 발전은 LLMs의 안전성을 강화하고, 더욱 견고한 방어 전략을 개발하는 데 있어 중요한 발판을 제공함. 연구자들은 이 기술을 활용하여 다양한 유형의 적대적 공격에 대응할 수 있는 방어 메커니즘을 개발할 수 있음.
    - 향후 연구에서는 AdvPrompter가 생성하는 적대적 접미사를 이용하여 LLMs를 미세 조정하는 과정을 통해, 모델의 취약점을 지속적으로 감지하고 개선하는 방법에 대해 더 깊이 탐구할 수 있음. 이는 자동화된 안전성 향상 방법론을 개발하는 데 중요한 기여를 할 수 있음.

# **Conclusion**

> 논문의 결론 부분에서는 'AdvPrompter'의 주요 성과와 잠재적인 영향력에 대해 요약하고, 연구의 한계점과 향후 방향을 제시. AdvPrompter가 LLMs의 안전성 향상에 중요한 기여를 할 수 있음을 강조하며, 이 기술이 가져올 장기적인 변화에 대한 기대감을 표현하고 있음.
> 
1. **주요 성과**:
    - 'AdvPrompter'는 대규모 언어 모델(LLMs)에 대한 적대적 프롬프트 생성을 자동화함으로써, 기존의 수동 및 시간 소모적인 방법보다 효율적으로 안전 취약점을 탐지하고 이를 개선할 수 있는 새로운 방법을 제공.
    - 실험 결과, AdvPrompter는 기존 방법에 비해 월등히 빠른 속도로 높은 자연스러움과 읽기 쉬운 적대적 접미사를 생성할 수 있으며, 이는 다양한 대상 LLMs에 대한 높은 공격 성공률을 달성하는 데 기여.
2. **연구의 한계와 향후 방향**:
    - 현재의 연구는 주로 오픈 소스 LLMs에 초점을 맞추었으나, 폐쇄 소스 또는 상업적 LLMs에 대한 추가적인 검증이 필요.
    - 미래 연구에서는 AdvPrompter를 활용한 자동화된 안전성 향상 방법론을 더 발전시킬 수 있으며, 이를 통해 LLMs의 안전성과 견고성을 지속적으로 강화하는 방법을 탐구할 수 있음.