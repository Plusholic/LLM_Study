# 3 LINE SUMMARY
- 기존의 조정 방법은 상당한 계산 비용과 특수 데이터를 필요로 하며, GPT 수준의 성능을 달성하기 위해 많은 자원을 요구함
- 연구진은 65B 파라미터의 LLaMa 언어 모델을 1,000개의 세심하게 큐레이션된 프롬프트와 응답으로만 튜닝하여 성능 향상을 이뤄냄
- 지식의 대부분을 사전 훈련 과정에서 습득하고, 제한된 지시 학습 데이터만으로도 높은 품질의 출력을 생성할 수 있음을 시사함

원문링크
[LIMA: Less Is More for Alignment](https://arxiv.org/abs/2305.11206)

# Abstract

> LIMA는 대규모 언어 모델로서, 두 단계로 훈련되었음. 첫 번째 단계는 비지도 학습을 통해 일반적인 표현을 배우고, 두 번째 단계는 지시 학습과 강화 학습을 통해 사용자의 요구와 과제에 더 잘 맞도록 조정됨. 연구진은 65B 파라미터의 LLaMa 언어 모델을 1,000개의 세심하게 큐레이션된 프롬프트와 응답으로만 튜닝하여 성능 향상을 이뤄냄.
> 
- 이 모델은 복잡한 질문에 대해서도 특정 응답 형식을 따르며, 훈련 데이터에 없는 새로운 작업에도 잘 일반화되는 경향을 보임.
- 인간 연구에서도 GPT-4, Bard, DaVinci003 등 다른 모델들과 비교했을 때, LIMA가 선호되거나 동등한 경우가 많았음
- 이 결과는 대규모 언어 모델이 지식의 대부분을 사전 훈련 과정에서 습득하고, 제한된 지시 학습 데이터만으로도 높은 품질의 출력을 생성할 수 있음을 시사함.

# 1. Introduction

> 강력한 사전 훈련된 언어 모델만으로도 1,000개의 세심하게 큐레이션된 훈련 예제로 미세 조정을 수행함으로써 놀라울 정도로 우수한 성능을 달성할 수 있음을 보여줌. 연구진은 이를 통해 모델이 사용자와 상호 작용하는 스타일이나 형식을 배우는 것이 가능하다는 가설을 세움.
> 
- 언어 모델은 토큰 예측을 통해 엄청난 규모로 사전 훈련됨. 이를 통해 언어 이해나 생성 작업에 거의 모든 언어에 전이 가능한 일반적인 표현을 학습할 수 있음.
- 최근에는 크게 주목받고 있는 언어 모델 조정 방법으로 instruction tuning이 있으며, 이는 대규모 다작업 데이터셋을 활용함
- 인간 피드백에서 강화 학습(RLHF)을 통해 수집된 수백만 개의 상호작용을 통한 학습도 포함
- 이러한 기존의 조정 방법은 상당한 계산 비용과 특수 데이터를 필요로 하며, GPT 수준의 성능을 달성하기 위해 많은 자원을 요구

# 2. Alignment Data

> LIMA 모델의 학습 데이터셋 구성과 그 목적에 대한 설명. 연구진은 1,000개의 프롬프트와 응답을 수집하여, 출력(응답)이 서로 스타일적으로 일치하면서도 입력(프롬프트)은 다양성을 유지하도록 설계함. 응답은 유용한 AI 비서의 스타일을 따르도록 큐레이션. 주요 데이터 소스로는 커뮤니티 Q&A 포럼과 수동으로 작성된 예제들 사용.
> 

![Untitled](table1.png)

## 2.1. Community Questions & Answers

- Stack Exchange, wikiHow, Pushshift Reddit Dataset에서 데이터를 수집한 방법을 설명.
- 전반적으로, Stack Exchange와 wikiHow의 답변들은 도움이 되는 AI 에이전트의 행동과 잘 일치하기 때문에 자동으로 채굴될 수 있음. 반면에, 높은 추천을 받은 레딧의 답변들은 주로 유머적이거나 트롤링하는 경향이 있어 적절한 스타일을 따르는 응답을 직접 선별하는 수작업이 필요함.

**Stack Exchange**

- 179개의 온라인 커뮤니티(exchanges)로 구성되어 있음. 각 커뮤니티는 특정 주제에 특화되어 있으며, 가장 인기 있는 것은 프로그래밍(Stack Overflow).
- 사용자들은 질문, 답변, 댓글을 게시하고 이들을 추천하거나 반대로 평가할 수 있음. 활발한 커뮤니티 회원과 모더레이터들 덕분에 스택 에스체인지는 콘텐츠 품질에 대한 높은 기준을 유지하고 있음.
- Stack Exchange에서 샘플링할 때 품질과 다양성 제어를 모두 적용함.
    - 먼저, 75개의 STEM Exchanges(프로그래밍, 수학, 물리학 등 포함)과 99개의 기타 교환(영어, 요리, 여행 등)으로 나누고, 5개의 niche exchanges는 제외.
    - 각 집합에서 다양한 도메인의 균일한 샘플을 얻기 위해 온도가 𝜏 = 3 인 200개의 질문과 답변을 추출.
    - 각 Exchange에서는 제목만으로 완결된 질문들 중에서 점수가 가장 높은 것들을 선택.
    - 그런 다음 각 질문에 대해 강한 양수 점수(적어도 10점)를 가진 최고의 답변을 선택.
    - 도움이 되는 AI 어시스턴트의 스타일에 부합하도록, 너무 짧은 답변(1200자 미만), 너무 긴 답변(4096자 이상), 제 1인칭으로 작성된 답변("나", "내" 등), 다른 답변을 참조하는 답변("언급한 바와 같이", "스택 에스체인지" 등)을 자동으로 필터링.
    - 답변에서 링크, 이미지 및 다른 HTML 태그를 제거하고, 코드 블록과 목록만을 유지. Stack Exchange의 질문은 제목과 설명이 모두 포함되어 있으므로, 일부 예시에는 제목을 무작위로 선택하고, 다른 예시에는 설명을 선택.

**wikiHow**

- 위키하우(wikiHow)는 다양한 주제에 대한 24만 개가 넘는 "어떻게 하는지" 기사를 실은 온라인 위키 스타일의 출판물.
- 누구나 위키하우에 기여할 수 있지만, 기사들은 심사가 엄격하게 이루어져 거의 일관된 높은 품질을 가짐.
- 위키하우에서 200개의 기사를 샘플링.
- 먼저 카테고리(19개 중 하나)를 샘플링한 다음 해당 카테고리 내의 기사를 선택하여 다양성을 보장.
- 우리는 제목을 프롬프트로 사용하고 (예: "계란 말이 요리법은?"), 기사의 본문을 응답으로 사용.
- "이 기사..."로 시작하는 전형적인 부분을 "다음 답변..."으로 바꾸고, 링크, 이미지 및 텍스트의 특정 부분을 제거하기 위해 여러 전처리 휴리스틱을 적용.

**Reddit**

- 레딧은 사용자가 생성한 서브레딧에서 콘텐츠를 공유, 토론 및 추천하는 사이트. 그 인기로 인해 레딧은 도움이 되는 것보다는 다른 사용자를 즐겁게 하는 데 더 중점을 두고 있음.
- 때때로 재치 있고 비꼬는 댓글이 진지하고 유익한 댓글보다 더 많은 투표를 받는 경우가 많기 때문에 r/AskReddit와 r/WritingPrompts 두 하위 집합으로 샘플을 제한하고 각 커뮤니티에서 가장 추천을 많이 받은 게시물 내에서 예제를 수동으로 선택.
- r/AskReddit에서는 70개의 완전한 프롬프트(제목만, 내용 없음)를 찾아서 테스트 세트로 사용. 상위 답변이 반드시 신뢰성이 있는 것은 아니기 때문.
- WritingPrompts 서브레딧에는 허구 이야기의 전제가 포함되어 있으며, 다른 사용자들은 이를 창의적으로 완성하도록 장려됨.
- 훈련 세트에 추가하기 위해 사랑 시와 짧은 과학 소설 등 다양한 주제를 포함한 150개의 프롬프트와 고품질의 답변을 찾음.
- 모든 데이터 인스턴스는 Pushshift Reddit Dataset [Baumgartner et al., 2020]에서 채굴됨.

## 2.2. Manually Authored Examples

- 저자들은 두 그룹(A와 B)으로 나뉘어 각각 250개의 프롬프트를 생성
- 200개는 훈련 데이터로, 나머지 50개는 개발 데이터로 사용.
- 수동으로 생성된 예제들은 일관된 톤을 유지하며 AI 비서에 적합한 응답 스타일을 갖도록 디자인.

# 3. Training LIMA

> LIMA는 LLaMa 65B 모델을 기반으로 하여, 1,000개의 예제를 이용해 조정됨. 이 과정에서는 각 발언의 끝에 특별한 end-of-turn (EOT) 토큰을 사용하여 사용자와 비서 간의 대화에서 구분을 두었습니다. 이 토큰은 기존 EOS 토큰과의 혼동을 피하기 위해 도입됨.
> 
- 훈련은 15 에폭 동안 진행되었으며, AdamW 최적화 알고리즘을 사용.
- 초깃값으로는 학습률을 1e-5로 설정하고, 훈련의 끝까지 선형적으로 1e-6으로 감소시킴.
- 배치 크기는 32였으며, 텍스트 길이가 2048 토큰을 초과하는 경우에는 자르도록 설정.
- Residual Dropout을 적용하여, 하위 계층에서는 0.0부터 시작해 최상위 계층에서 0.3까지 비율을 높여감.
- 성능 평가는 5~10 epoch에서 수동으로 체크포인트를 선택.
- 연구진은 복잡성을 증가시키지 않고도, 한정된 데이터로도 효과적인 조정이 가능함을 보여주었습니다.

# 4. Human Evaluation

> LIMA는 다른 언어 모델들, 특히 OpenAI의 RLHF 기반 DaVinci003 및 Alpaca 65B 모델과 비교하여 뛰어난 성능을 보여줌. GPT-4, Claude, Bard와 비교해도 LIMA의 응답은 동등하거나 더 선호되었음.
> 

## 4.1. Experiment Setup

- 각 테스트 프롬프트에 대해 각기 다른 모델에서 생성된 단일 응답을 평가하도록 설계하였음.
- 평가는 크라우드 워커들과 GPT-4를 사용하여 수행되었으며, 응답자들은 두 가지 응답을 비교하고 더 나은 응답을 선택하도록 요청받음.

**Generation**

- 각 프롬프트에 대해, 우리는 각 베이스라인 모델로부터의 단일 응답을 사용하여 확률 분포 샘플링(nucleus sampling) [Holtzman et al., 2019]을 이용, 𝑝 = 0.9, 온도(temperature)는 𝜏 = 0.7
- 이전에 생성된 토큰들에 대한 repetition penalty 1.2로 설정합니다 [Keskar et al., 2019].
- 최대 토큰 길이를 2048로 제한.

**Methodology**

- 주석자에게 하나의 프롬프트와 서로 다른 모델로부터 생성된 두 가지 가능한 응답을 제시.
- 주석자들은 어떤 응답이 더 나은지를 라벨링하거나, 어느 쪽이나 다른 쪽보다 유의미하게 나은 것이 없는지를 결정(Appendix C)
- 동일한 지시와 데이터를 제공함으로써 GPT-4가 완전히 동일한 주석을 수집하도록 함.(Appendix D)

**Inter-Annotator Agreement**

- 주석자 간 일치도를 계산하기 위해 일치하지 않는 결과에 패널티를 적용하는 tie-discounted accuracy를 사용.
- 만약 두 주석자가 동의한 경우에는 한 점을 할당하고, 어느 주석자 한 명이 비견사를 지정한 경우에는 절반의 점을, 그 외의 경우에는 점수를 부여하지 않음.
- 우리는 50개의 주석 예시(단일 프롬프트, 무작위로 선택된 두 모델 응답)에 대해 작성자, 대중 및 GPT-4 주석을 비교하여 주석자 간 일치를 측정.
- 인간 주석자들 사이의 일치도 점수.
    - crowd-crowd 82%
    - crowd-author 81%
    - author-author 78%
- 주관적인 작업임에도, 인간 주석자들 일치 비율이 높았ㅎ음.
- GPT-4와 인간 간의 일치도를 점수
    - crowd-GPT 78%
    - author-GPT 79% (비록 우리가 확률적 디코딩을 사용하지만, GPT-4는 거의 항상 자신과 일치합니다). 이 수치들은 GPT-4가 인간 주석자들과 일치하여 이 작업에 대한 Turking 테스트를 통과했다는 것을 의미합니다[Efrat and Levy, 2020].
        - Turking Test는 인공 지능이 인간과의 상호 작용에서 인간과 구별할 수 없는 수준에 도달했는지를 확인하는 테스트.
        - 이것은 주로 터크(Turker)라고 불리는 온라인 마이크로 작업자들을 사용하여 수행.
        - 인공 지능 모델이 인간과 유사한 수준으로 작업을 수행하거나 인간과의 상호 작용에서 거의 동일한 행동을 보이는 경우, 해당 인공 지능이 터킹 테스트를 통과했다고 말할 수 있음.

## 4.2. Results

- 결과에 따르면, LIMA는 Alpaca 65B보다 일반적으로 더 선호되는 출력을 생성
- RLHF로 훈련된 DaVinci003에 비해서도 우수한 경우가 많았음.
- Bard와 비교할 때는 LIMA의 응답이 58%의 경우에서 최소한 동등하거나 더 좋았음.

![Untitled](figure1.png)

## 4.3. Analysis

- LIMA 응답의 질을 더 자세히 분석하며, 특정 실험 조건에서 LIMA가 어떻게 성능을 발휘하는지 설명.
- 50개의 테스트 프롬프트를 분석하여 실패, 통과, 탁월함을 기준으로 각 응답을 분류.
- LIMA는 탁월한 응답을 많이 생성했으며, 그중 50%가 우수한 반응으로 평가됨.

![Untitled](figure3.png)

Result

- Figure 3은 LIMA 답변의 50%가 우수하다고 여겨지며, 분석된 50개의 프롬프트 중 6개를 제외한 모두를 따르는 것을 보여줌.
- 실패한 경우 내에서 특이한 경향을 관찰하지 못했습니다.
- Figure 4는 육아 조언과 레시피 생성에 대한 예시 LIMA 출력.

**Out of Distribution**

- LIMA가 어떻게 수행되는지 50개의 분석된 예제 중 43개에는 형식적으로 관련된 훈련 예제가 존재(예: 질문 응답, 조언, 편지 작성 등).
- 13개의 추가적인 분포 밖 예제를 분석하고(총 20개), 응답의 20%가 실패하고, 35%가 통과되며, 45%가 우수하다는 것을 발견.
- 이것은 작은 샘플이지만, LIMA가 훈련 분포 밖에서도 유사한 절대 성능 통계를 달성한다는 것을 시사, 이는 LIMA가 잘 일반화되었다는 것을 시사함.
- Figure 4는 스탠드업 코메디 작성이나 피자 주문에 대해 LIMA의 반응을 보여줍니다.

**Safety**

- 마지막으로, 우리는 훈련 세트에 작은 수의 안전 관련 예제(단 13개; 섹션 2.2 참조)가 있는 경우의 효과를 분석합니다.
- 우리는 테스트 세트의 30가지 잠재적으로 민감한 프롬프트에 대한 LIMA의 응답을 확인하고, LIMA가 80%의 경우 안전하게 응답하는 것을 발견(악의적인 의도를 가진 10개의 프롬프트 중 6개를 포함).
- 경우에 따라 LIMA는 작업을 수행하지 않는 경우도 있음(예: 유명인의 주소 제공 요청 시), 하지만 악의적인 의도가 내재된 경우 LIMA는 더 불안전한 응답을 제공할 가능성이 높음.
- Figure 4에서 확인할 수 있습니다.

# 5. Why is Less More? Ablations on Data Diversity, Quality, and Quantity

> 데이터의 다양성, 품질, 양이 언어 모델의 조정에 어떤 영향을 미치는지에 관한 내용. 주된 관심사는 입력의 다양성과 출력의 품질을 높이는 것이 어떻게 언어 모델의 성능에 긍정적인 영향을 미치는지, 반면 단순히 데이터 양을 늘리는 것만으로는 큰 효과가 없을 수 있음을 보여줌.
> 
- 연구진은 7B 파라미터 LLaMa 모델을 다양한 데이터셋에서 미세 조정하여 실험을 수행.
    - Stack Exchange 데이터는 프롬프트의 다양성과 우수한 응답으로 구성
    - wikiHow 데이터는 동질적인 프롬프트와 우수한 응답으로 구성.
    - 결과적으로, Stack Exchange 데이터로 훈련된 모델이 wikiHow 데이터로 훈련된 모델보다 더 높은 성능을 보였음.
- 품질에 관한 실험에서는, 품질과 스타일이 제어된 데이터셋으로 훈련한 모델이 품질 제어가 없는 데이터셋으로 훈련한 모델보다 상당히 더 나은 결과.
- 이는 응답의 품질이 모델의 성능에 중요한 영향을 미친다는 것을 강조.
- 데이터 양에 관한 실험에서는, 데이터의 양을 증가시킬 때 성능 향상이 눈에 띄지 않았음.
    - 언어 모델의 fine tuning에서 데이터의 양보다는 다양성과 품질이 더 중요한 요소라는 것을 시사.

![Untitled](figure4_1.png)

![Untitled](figure4.png)

![Untitled](figure5.png)

# 6. Multi-Turn Dialogue

> 단일 턴 대화에 기반한 훈련 데이터만 사용하여 다중 턴 대화를 얼마나 효과적으로 수행할 수 있는지를 탐구. 연구진은 LIMA를 사용하여 10번의 실시간 대화를 진행하고, 각 응답을 실패, 통과, 뛰어남으로 분류. LIMA는 초기 턴에서 정보를 참조하며 상당히 일관된 대화를 유지할 수 있었지만, 대화가 진행될수록 주제를 따라가지 못하는 경우가 있었음.
> 
- 연구진은 대화 능력을 개선하기 위해 30개의 다중 턴 대화 체인을 추가로 수집함. 이 중 10개는 저자가 직접 작성하고, 나머지 20개는 Stack Exchange의 댓글에서 가져와 비서의 스타일에 맞게 수정.
- 아래 Figure에서, 왼쪽과 오른쪽에서 같은 질문에 대한 다른 품질의 답변을 확인할 수 있음.
- 이 새로운 데이터셋을 포함하여 LIMA를 다시 훈련시킨 결과, 모델의 대화 생성 품질이 크게 향상됨. 추가된 대화 예제를 포함한 버전의 LIMA는 실패율을 크게 감소시키고, 우수한 응답의 비율을 높였음.
- 이 결과는 사전 훈련된 모델이 제한된 감독 하에도 필요한 기능을 발휘할 수 있음을 시사하며, 적은 수의 대화 예제만으로도 모델의 대화 능력을 상당히 향상시킬 수 있음을 보여줌. 이는 사전 훈련이 언어 모델에게 매우 중요한 역할을 한다는 것을 다시 한번 확인시켜 줌.
    
    ![Untitled](figure8.png)
    

# 7. Discussion

> 연구진은 강력한 사전 훈련된 언어 모델이 1,000개의 세심하게 큐레이션된 예제만으로도 놀라운 결과를 낼 수 있다는 점을 강조. 이는 고도로 맞춤화된 소수의 예제를 통해 모델이 사용자의 요구와 일치하는 방식으로 행동하도록 학습할 수 있음을 보여줌.
> 
- 그러나 이러한 접근 방식에는 몇 가지 한계가 존재.
    1. 고품질의 예제를 구성하는 데 필요한 정신적 노력은 상당하며, 이를 대규모로 확장하는 것은 어려움.
    2. LIMA는 제품급 모델만큼 견고하지 않을 수 있으며, 특정 조건에서는 취약한 반응을 보일 수 있음. 특히, unlucky sample이나 adversarial prompt에 의해 weak response가될 수 있음.
- 연구진은 이러한 결과를 바탕으로, 언어 모델의 정렬 문제를 간단한 접근법으로 해결할 수 있는 가능성을 제시
- 본 논문은 대규모 지시 학습 및 강화 학습 방법에 비해 사전 훈련의 상대적 중요성을 강조하면서, 이를 통해 모델이 고품질의 출력을 생성할 수 있는 능력을 갖추었다고 결론.

# Appendix

## A. Training Examples

> LIMA 모델을 훈련시키는 데 사용된 다양한 출처의 훈련 예제들을 제공. 예제들은 크게 커뮤니티 Q&A와 수동으로 작성된 예제로 나뉨.
> 

**커뮤니티 Q&A 예제**

- 이들은 Stack Exchange, wikiHow, 그리고 Pushshift Reddit Dataset에서 추출된 데이터를 포함
- 예를 들어, Stack Exchange에서는 고품질의 질문과 답변을 선정하여 LIMA의 훈련 데이터로 사용하였으며, wikiHow 기사는 '어떻게 하나요?' 형식의 질문과 상세한 답변으로 구성됨.
- Reddit 데이터셋에서는 주로 유머나 트롤링 응답을 걸러내고, 도움이 되는 AI 비서 스타일의 응답을 수동으로 큐레이션.

**수동으로 작성된 예제**

- 연구진은 특정 테마나 상황에 맞춰 직접 예제를 작성.
- 이러한 예제들은 다양한 사용 사례를 모델에 제공하고, 일관된 응답 스타일을 유지하도록 돕기 위해 설계됨.
- 예제의 내용은 일상 대화, 조언, 또는 정보 제공 등 다양.

## B. Anticorrelation between Perplexity and Generation Quality

> LIMA 모델을 미세 조정하는 동안 관찰된, perplexity(혼란도)와 생성 품질 간의 반상관 관계에 대해 설명. 일반적으로 모델의 perplexity가 낮을수록 더 나은 언어 이해를 나타내며, 이는 일반적으로 높은 품질의 텍스트 생성과 연관됨. 그러나 LIMA 모델의 경우, 훈련 과정에서 perplexity가 증가함에도 불구하고 생성 품질이 향상되는 현상이 관찰됨.
> 
- 이러한 현상을 정량화하기 위해 ChatGPT를 사용하여 모델의 생성물을 평가. 특히, 다양한 훈련 단계에서 생성된 텍스트의 품질을 평가하고, 이를 perplexity와 비교.
- 특정 훈련 단계에서 perplexity가 증가함에도 불구하고 생성 품질이 개선되었음이 확인됨.
- 모델의 훈련 과정에서 perplexity만을 성능 지표로 사용하는 것의 한계를 시사
- 모델의 실제 출력 품질을 평가하기 위해 보다 복잡한 방법이 필요함을 제안합니다.
- 또한, 이는 perplexity가 항상 생성 품질과 직접적인 상관관계를 가지지 않을 수 있음을 보여줌, 훈련 프로세스에서 다양한 요소를 고려할 필요가 있음.

## C. Human Annotation

> 인간 평가자들이 LIMA 모델과 다른 언어 모델들의 응답을 비교 평가하는 과정에 사용된 주석 방법과 인터페이스에 대해 설명. 연구진은 언어 모델들의 생성물을 객관적이고 일관된 방식으로 평가하기 위해 세심하게 설계된 인간 주석 프로세스를 개발.
> 
- 주석 인터페이스는 사용자에게 한 가지 질문과 그에 대한 두 가지 다른 모델의 응답을 제시함.
- 평가자는 두 응답을 비교하고 다음 세 가지 옵션 중 하나를 선택:
    1. 응답 A가 현저하게 더 낫다.
    2. 응답 B가 현저하게 더 낫다.
    3. 두 응답 모두 유의미하게 나은 것은 아니다.
- 평가자들은 각 응답의 도움이 됨, 정확성, 표현의 명확성을 기준으로 응답을 평가하도록 요청됨
- 이러한 주석 프로세스를 통해 연구진은 모델들의 성능을 정확하게 비교할 수 있었음
    
    ![Untitled](figure11.png)
    

## D. ChatGPT Score

> 언어 모델의 생성물을 자동으로 평가하기 위해 사용된 ChatGPT 점수에 대한 설명. 연구진은 특히 LIMA 모델의 성능 향상 실험을 위해 개발된 이 점수 시스템을 사용하여, 모델이 생성한 텍스트의 도움이 됨을 6점 리커트 척도로 평가. 이 척도는 1에서 6까지의 점수로, 생성된 텍스트가 사용자의 질문에 얼마나 잘 대답하는지를 평가하는 데 사용됨.
> 
- 리커트 척도는 다음과 같이 정의:
    - 1: 도움이 되지 않음 - 생성된 텍스트가 완전히 관련 없거나 불명확하거나 불완전.
    - 2: 다소 도움이 됨 - 텍스트에 일부 관련성은 있지만 명확하지 않거나 완전하지 않음.
    - 3: 적당히 도움이 됨 - 텍스트가 관련성이 있고 명확하며 완전한 답변을 제공.
    - 4: 도움이 됨 - 텍스트가 매우 관련성이 있고 명확하며 상세한 답변을 제공.
    - 5: 매우 도움이 됨 - 텍스트가 사용자의 질문에 대해 매우 유용하고 통찰력 있는 추가 정보를 제공.
    - 6: 매우 매우 도움이 됨 - 텍스트가 명확하고 상세하며, 유용한 추가 정보나 설명을 제공.
- ChatGPT 점수 시스템은 GPT-3.5 Turbo를 사용하여 구현되었으며, 각 테스트 케이스에 대한 자동 평가를 수행함으로써 실험의 효율성을 높이고, 인간 평가자의 주관적 판단을 보완함.
- 이 점수 시스템을 사용함으로써, 연구진은 다양한 조건과 실험 설정에서 모델의 성능을 빠르고 일관되게 평가할 수 있었음.
    
    ![Untitled](figure12.png)
    

# E. Generating Text with Complex Structure

> LIMA 모델이 복잡한 구조의 텍스트를 생성할 수 있는지, 그리고 이를 위해 추가된 몇 가지 구조 지향 훈련 예제가 모델의 성능에 어떤 영향을 미쳤는지를 탐구. 연구진은 특히 구조가 명확한 텍스트 요구 사항, 예를 들어 글을 요약하거나 특정 형식으로 정보를 제공하는 작업에 모델이 어떻게 반응하는지에 집중함.
> 
- 연구진은 모델의 초기 버전이 복잡한 구조 요구를 일관되게 충족시키지 못한다는 것을 발견하고, 이를 개선하기 위해 특정 형식 지시를 포함한 6개의 추가 훈련 예제를 도입함.
- 이러한 예제들은 제품 페이지 생성, 문서 요약, 질문-답변 쌍 생성 등 다양한 형식을 포함.
- 이 추가된 예제들은 모델이 구조적 요구 사항을 더 잘 이해하고 충족할 수 있도록 도왔습니다.
- 훈련 후, 연구진은 모델이 구조 지향적 요구가 있는 새로운 프롬프트에 대해 향상된 반응을 보이는지를 평가.
- 결과적으로, 추가된 구조 지향 훈련 예제를 포함한 모델은 초기 버전보다 훨씬 더 정교하고 복잡한 구조의 텍스트를 생성할 수 있었음.
- 이러한 결과는 복잡한 텍스트 생성에 있어 훈련 데이터의 질과 다양성이 중요하다는 것을 다시 한번 확인시켜 줌