
![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/19fd67b1-0aa7-45f9-9b6d-a8b441f60733/ac6c9534-4dbc-4618-b344-6fd300b8822d/image.png)

# Abstract

> 비디오 생성은 비디오 길이, 디테일 등에서 상당한 도전에 직면해 있음. 이 연구에서는 "MimicMotion"이라는 이름의 비디오 생성 프레임워크를 제안. 이 프레임워크는 특정 모션 가이던스를 모방하여 고품질의 비디오를 임의의 길이로 생성할 수 있음.
> 
- 신뢰도 기반 포즈 가이던스를 도입하여 프레임의 품질과 시간적 매끄러움을 보장
- 포즈 신뢰도를 기반으로 한 영역별 손실 증폭을 통해 이미지 왜곡을 크게 줄임
- 점진적 잠재 융합 전략을 통해 자원 소비를 적정 수준으로 유지하면서 길고 부드러운 비디오를 생성할 수 있음

# Introduction

> 비디오 생성은 여전히 제어 가능성, 비디오 길이, 디테일의 풍부함 등 여러 측면에서 상당한 도전에 직면하고 있음. 이 연구에서는 포즈 가이던스를 기반으로 한 비디오 생성에 중점을 두고 있으며, 참조 이미지와 일치하는 동시에 풍부한 디테일을 포함하는 비디오를 생성하는 것을 목표로 함. 기존의 이미지 기반 포즈 가이던스 비디오 생성 방법들은 여러 기술적 한계를 가지고 있음
> 
- 현재, 이미지 기반 포즈 가이던스 비디오 생성에 관한 많은 연구들이 진행되고 있으며, Follow Your Pose, DreamPose, DisCo, MagicDance, AnimateAnyone, MagicAnimate, DreaMoving, Champ 등의 모델들이 존재.
    - 다양한 모델 아키텍처와 학습 기법이 연구되었음에도 불구하고, 생성된 결과는 여러 면에서 만족스럽지 않음.
    - 특히 사람의 손과 같은 영역에서 이미지 왜곡이 발생하는 것이 일반적이며, 큰 움직임이 포함된 비디오에서 이 문제가 더욱 두드러짐.
    - 시간적 매끄러움을 달성하기 위해 이미지 디테일이 희생되어 흐릿한 프레임이 생성되는 경우가 있음.
    - 계산 자원과 모델의 능력 제한으로 인해 다수의 프레임을 포함하는 고품질의 긴 비디오를 생성하는 것 역시 여전히 큰 도전 과제임.
- 부정확한 포즈 추정의 부정적인 영향을 줄이기 위해, 우리는 신뢰도 기반의 포즈 가이던스 접근 방식을 제안.
- 포즈 시퀀스 표현에 `신뢰도 개념을 도입`함으로써 더 나은 시간적 매끄러움이 달성되고 이미지 왜곡도 완화될 수 있음.
- 신뢰도 기반의 영역 손실 증폭은 `손 영역을 더욱 정확하고 선명하게 만들어줌.` 또한, 제안된 프로그레시브 잠재 융합 방법을 통해 길고도 매끄러운 비디오 생성을 달성할 수 있음.
- 중첩된 프레임을 가진 비디오 세그먼트를 생성하고, 이러한 세그먼트를 병합하여 최종적으로 크로스-프레임 매끄러움과 이미지 풍부함을 모두 갖춘 긴 비디오를 생성할 수 있음.
- 모델 훈련에서는 훈련 비용을 적정 수준으로 유지하기 위해 일반적으로 사전 학습된 비디오 생성 모델을 기반으로 하며, 많은 양의 훈련 데이터가 필요하지 않고 특별한 수동 주석도 요구되지 않음.

1. Confidence-Aware전략을 통해 포즈 가이던스를 개선하여 부정확한 포즈 추정의 부정적인 영향을 완화. 이 접근 방식은 훈련 중 노이즈가 많은 샘플의 영향을 줄일 뿐만 아니라 추론 중 잘못된 포즈 가이던스를 교정.
2. Confidence-Aware전략을 바탕으로 손 영역 강화 방식을 제안하여, 높은 포즈 신뢰도를 가진 손 영역의 손실 가중치를 강화함으로써 손 왜곡을 완화합니다.
3. Cross-Frame Overlapped Diffusion은 긴 비디오 생성의 표준 기법이지만, 우리는 세그먼트 경계에서 시간적 매끄러움을 개선하는 Position-Aware Progressive Latent Fusion Approach를 제안합니다. 광범위한 실험 결과는 제안된 접근 방식의 효과를 입증하였음.

# Relative Work

**Diffusion models for image/video generation**

- Diffusion 모델은 이미지와 비디오 생성에서 뛰어난 성능을 보여주었으며, Latent Diffusion Models (LDM)을 통해 고해상도 이미지를 효율적으로 생성할 수 있음.
- 이 방법은 저차원 잠재 공간에서 확산 과정을 수행함으로써 계산 비용을 절감하고 생성 품질을 향상시킴.
- 비디오 생성의 경우, 시간적 계층을 추가하거나 트랜스포머 구조를 활용하여 생성 능력을 증대시키는 연구들이 진행되고 있음.

**Pose-guided human motion transfer**

- Pose-to-apperance 매핑은 원본 이미지의 모션을 타겟 이미지로 전이하는 것을 목표로 함.
- 이 과정에서 로컬 아핀 변환이나 Thin-Plate Spline 변환을 사용하여 왜곡을 최소화하고, 생성된 이미지가 주어진 포즈를 최대한 닮도록 함.
- 이 연구에서는 기존 기법들과 달리 신뢰도 기반의 포즈 가이던스를 도입하여 부정확한 포즈 추정의 영향을 줄이고, 손 영역과 같은 세밀한 부분의 품질을 향상시켰음.

**Long video generation**

- 기존의 diffusion 기반 비디오 생성 알고리즘은 짧은 길이의 비디오 생성에 제한되었음.
- 이를 극복하기 위한 방법으로 MultiDiffusion을 사용하여 비디오를 여러 세그먼트로 나누고 각 세그먼트를 독립적으로 디노이징한 후, 최적화 알고리즘을 통해 이들을 결합하는 방법이 있음.
- 본 연구에서는 이러한 기존 접근법을 발전시켜 세그먼트 경계에서 시간적 부드러움을 향상시키는 위치 인식 기반의 점진적 잠재 융합 전략을 제안.

# Methods

## 3.1 Preliminaries

- Diffusion 모델은 주어진 데이터셋에 대한 확률 분포를 생성하는 과정으로, 노이즈가 추가된 데이터를 점진적으로 복구하여 새로운 데이터를 생성하는 방법
    - 구체적으로, 마르코프 연쇄(Markov Chain)로 정의된 고정된 과정에서 데이터에 가우시안 노이즈를 점진적으로 추가.
    - 그런 다음, 노이즈가 포함된 데이터를 역순으로 복구하는 함수(ϵθ)를 신경망을 통해 학습하여, 이 신경망을 사용해 무작위 노이즈로부터 새로운 데이터를 생성.
    - 

## 3.2 Data preparation

- 포즈 가이던스 기반의 비디오 확산 모델을 훈련하기 위해 다양한 인간 동작을 포함하는 비디오 데이터셋을 수집.
- 이 데이터셋은 사전 학습된 이미지-비디오 모델의 강력한 성능을 활용하여 비교적 작은 규모로 구성됨.
- 각 비디오 샘플은 참조 이미지(Iref), 원시 비디오 프레임 시퀀스, 그리고 해당하는 포즈로 구성됨.
- 비디오 프레임은 고정된 종횡비를 가지도록 크기 조정과 자르기 등의 전처리 작업을 거치며, 참조 이미지는 동일한 비디오에서 무작위로 선택되어 비디오 프레임과 동일한 방식으로 전처리됨.
- 또한, 포즈 시퀀스는 DWPose를 사용하여 비디오 프레임으로부터 프레임별로 추출됨.

## 3.3 Pose-guided Video Diffusion Model

- `이 모델의 목표는 단일 참조 이미지와 포즈 시퀀스를 기반으로 고품질의 인간 비디오를 생성하는 것.`
- 사전 학습된 비디오 확산 모델을 활용하여 데이터 요구 사항과 계산 비용을 줄임.
- MimicMotion은 Stable Video Diffusion(SVD) 모델을 기반으로 하며, 이미지에서 비디오로의 생성 능력을 활용.
- 이 모델은 Latent Diffusion Model(LDM)을 사용하여 픽셀 공간에서 고비용으로 진행되는 확산 과정을 저차원 잠재 공간에서 수행함으로써 효율성을 높임.
- `VAE 인코더와 디코더는 입력 비디오 프레임과 참조 이미지에 독립적으로 적용되며,` 시간적 또는 크로스 프레임 상호작용을 고려하지 않음.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/19fd67b1-0aa7-45f9-9b6d-a8b441f60733/cd9fef12-eca4-4c81-9e3e-afe3ba2e8066/image.png)

- 참조 이미지는 U-Net의 각 블록에 입력되며, 시각적 인코더를 통해 이미지 특징이 추출되고, U-Net 블록의 Cross-Attention에 전달됩니다.
- 포즈 가이던스를 도입하기 위해 PoseNet이라는 모듈을 설계.
    - 여러 개의 컨볼루션 레이어로 구현되며, 입력된 포즈 시퀀스의 특징을 추출하는 학습 가능한 모듈.
    - VAE 인코더를 사용하지 않은 이유는 포즈 시퀀스의 픽셀 값 분포가 일반적인 이미지와 다르기 때문.
    - PoseNet을 통해 추출된 포즈 특징은 U-Net의 첫 번째 컨볼루션 레이어의 출력에 요소 단위로 추가.
    - 이렇게 함으로써 디노이징 과정의 초기부터 포즈 가이던스의 영향을 받을 수 있음.
- 포즈 가이던스를 U-Net의 모든 블록에 추가하지 않은 이유는 다음과 같음
    - `포즈 시퀀스가 프레임별로 추출되어 시간적 상호작용이 없기 때문에, 이러한 특징이 U-Net의 시공간 레이어에 직접적으로 영향을 미치면 혼란을 초래할 수 있음.`
    - `포즈 시퀀스의 과도한 사용은 사전 학습된 이미지-비디오 모델의 성능을 저하시킬 수 있음.`

## 3.4 Confidence-aware pose guidance

- 비디오 생성 모델에서 부정확한 포즈 추정이 미치는 부정적인 영향을 완화하기 위한 방법을 제안.
    - 이 방법은 포즈 추정 모델로부터 얻은 각 키포인트의 신뢰도 점수를 활용.
    - 높은 신뢰도 점수는 정확한 감지 가능성을 나타내며, 낮은 신뢰도는 가려짐이나 움직임으로 인한 블러를 의미.
    - 이러한 신뢰도 점수를 이용해 모델이 더 신뢰할 수 있는 포즈 정보를 우선적으로 사용할 수 있게 하여, 생성되는 비디오의 정확도를 향상시킴. 이 접근 방식은 특히 움직임이 많은 영역에서 시각적 왜곡을 줄이는 데 효과적.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/19fd67b1-0aa7-45f9-9b6d-a8b441f60733/76327f8f-5db2-45c9-818b-c09520901b72/image.png)

- 손 왜곡과 같은 특정 영역의 시각적 아티팩트를 완화하기 위해 신뢰도 기반의 영역 손실 증폭 방법도 도입.
    - 키포인트의 신뢰도 점수에 따라 영역을 마스킹하고, 신뢰도가 높은 영역은 손실 계산 시 더 큰 가중치를 부여하여 훈련 중 이들 영역이 더 큰 영향을 미치도록 합니다.
    - 이로 인해 모델이 손과 같은 세밀한 부분에서 왜곡을 줄이고 더 현실적인 비디오 콘텐츠를 생성할 수 있음

## 3.5 Progressive latent fusion for long video generation

- 긴 비디오를 생성하는 데 있어서 계산 자원의 제한으로 인해 발생하는 문제를 해결하기 위한 방법을 제안.
- MultiDiffusion과 같은 기존의 접근 방식을 확장하여, 시간적으로 오버랩되는 비디오 세그먼트를 생성하고, 이러한 세그먼트들을 결합하여 매끄러운 비디오를 생성하는 방법이 존재.
    - 이러한 방법에서는 세그먼트 경계에서 갑작스러운 전환이 발생할 수 있음.
    - 이를 해결하기 위해, 저자는 Progressive Latent Fusion Strategy전략을 제안합니다.
- 이 전략은 세그먼트 경계에서의 매끄러운 전환을 보장하기 위해, 시간적 위치에 따라 융합 가중치를 점진적으로 조정.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/19fd67b1-0aa7-45f9-9b6d-a8b441f60733/06767478-ace1-431c-9d3c-2d9b317d7929/image.png)