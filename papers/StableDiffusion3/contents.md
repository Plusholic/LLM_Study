# Abstract

> **확산 모델 (Diffusion Models)은** 데이터에서 노이즈로의 경로를 반전시켜 데이터를 생성하는 기법. 고차원 및 Perceptual Data(이미지, 비디오 등)를 생성하는 강력한 기법으로 부상하였음. **Rectified Flow는** 데이터와 노이즈를 직선으로 연결하는 새로운 생성 모델 방식으로, 이론적으로 더 우수하지만 아직 널리 사용되지 않았음.
> 
- Rectified Flow 모델 훈련을 위해 지각적으로 관련 있는 스케일로 편향된 노이즈 샘플링 기법을 도입.
- Text-to-Image 생성을 위한 새로운 트랜스포머 기반 아키텍처를 제시. 이 아키텍처는 두 가지 모달리티(텍스트와 이미지)에 대해 별도의 가중치를 사용하고, 이미지와 텍스트 토큰 간의 양방향 정보 흐름을 가능하게 하여 텍스트 이해, 타이포그래피, 그리고 사람 선호도 평가를 개선함.
- **모델 확장성**을 예측 가능한 스케일링 트렌드를 따르며, Lower Validation Loss가 더 나은 Text-to-Image systhesis 성능과 상관관계가 있음을 보임.
- **기존 최고 수준의 모델보다 우수함**을 증명하고, 실험 데이터, 코드 및 모델 가중치를 공개할 예정.

# Introduction

> 확산 모델은 노이즈에서 데이터를 생성합니다, 그들은 데이터의 정방향 경로를 역전시키기 위해 훈련되어 무작위 노이즈로 변환됨. 따라서 신경망의 근사화 및 일반화 특성과 결합하여 훈련 데이터에는 존재하지 않지만 `훈련 데이터의 분포를 따르는 새로운 데이터 포인트를 생성하는 데 사용될 수 있음`. 데이터에서 노이즈로의 전방 경로를 지정하는 것은 효율적인 훈련을 이끌어내지만, 어떤 경로를 선택해야 하는지에 대한 문제가 생김. 예를 들어, 데이터에서 모든 노이즈를 제거하지 못하는 전방 과정은 훈련 및 테스트 분포의 불일치를 초래하고 회색 이미지 샘플과 같은 아티팩트를 초래할 수 있음. 중요한 점은 전방 과정의 선택이 역방향 과정 및 샘플링 효율성에도 영향을 준다는 것임. 곡선 경로는 프로세스를 시뮬레이션하기 위해 많은 통합 단계를 필요로 하지만, 직선 경로는 단일 단계로 시뮬레이션할 수 있으며 오류 누적 가능성이 적다. 각 단계가 신경망의 평가에 해당하기 때문에 이는 샘플링 속도에 직접적인 영향을 주게 됨.
> 
- 특정한 선택인 Forward path의 경우, Recitified Flow라고 불리는 것이 있음. 이는 데이터와 노이즈를 직선으로 연결. 이 모델 클래스는 이론적 특성이 더 우수하지만, 아직 실무에서 명확하게 확립되지는 않았음
- 본 연구에서는 이를 바꾸기 위해 Recitified flow 모델에서 노이즈 스케일을 재조정하여 소음 예측 확산 모델과 유사한 방식으로 소개.
- 모델에 이미지 및 텍스트 토큰에 대한 학습 가능한 스트림을 통합하는 새로운 아키텍처를 제시하고, 이를 통해 두 가지 정보 간에 양방향 흐름을 가능하게 함.
- 이를 개선된 정류된 흐름 공식과 결합하고, 그 확장성을 조사합니다. 검증 손실에서 예측 가능한 스케일링 경향을 보여주며, 낮은 검증 손실이 향상된 자동 및 인간 평가와 강한 상관 관계가 있음을 보여줌.

### 핵심 기여

1. 다양한 확산 모델 및 Recitified Flow 공식에 대한 대규모 체계적 연구를 수행하여 최적 설정을 식별. 이를 위해, 우리는 이전에 알려진 샘플러보다 성능을 향상시키는 교정된 플로우 모델을 위한 새로운 노이즈 샘플러를 소개.
2. 텍스트에서 이미지로의 합성을 위한 혁신적이고 확장 가능한 아키텍처를 고안함. 이 아키텍처는 네트워크 내에서 텍스트 및 이미지 토큰 스트림 간의 양방향 혼합을 허용.
3. 모델의 스케일링 연구를 수행하고 예측 가능한 스케일링 트렌드를 보여줌. 우리는 낮은 검증 손실이 T2I-CompBench (Huang et al., 2023), GenEval (Ghosh et al., 2023) 및 인간 평가와 같은 메트릭을 통해 평가된 텍스트에서 이미지로의 성능 향상과 강한 상관 관계가 있음을 보여줌.

# Simulation-Free Training of Flows

노이즈 분포 $p_1$에서 데이터 분포 $p_0$로 샘플을 변환하는 생성 모델을 다룹니다. 이를 위해 Ordinary Differential Equation (ODE)을 사용하여 다음과 같이 정의합니다:

$$
dy_t = v_Θ(y_t, t) d_t
$$

- $dy_t \over dt$ : 시간 $t$에 따른 변화율
- $v_Θ(y_t, t)$ : $v$는 신경망의 가중치 $Θ$에 의해 매개변수화된 속도.
- `이전 연구는 ODE 솔버를 통해 이 방정식을 직접 해결하는 방법을 제안`했지만, 이는 대규모 네트워크 아키텍처에 대해 계산량이 높음
- 효율적인 대안은 $p_0$과 $p_1$사이의 확률 경로를 생성하는 벡터 필드 $u_t$를 직접 회귀하는 것.
- $u_t$를 만들기 위해 forward process를 정의해야 함. $p_0$에서 $p_1 = \mathcal{N}(0, 1)$ 사이의 확률 경로 $p_t$

$$
z_t = a_tx_0 + b_t\epsilon \ \ \ \ where \ \ \ \ \epsilon \sim \mathcal{N}(0, 1)
$$

- $a_0 = 1, b_0 = 0, a_1 = 0, b_1 = 1$에 대해서,

$$
p_t(z_t) = \mathbb{E}_{\epsilon\sim\mathcal{N}(0, 1)}p_t(z_t|\epsilon)
$$

- 는 데이터의 노이즈 분포와 일치함
- **$z_t, x_0, \epsilon$의 관계를 표현하기 위하여 $\psi_t, u_t$를 사용함**

$$
\begin{aligned}
𝜓_𝑡(⋅|𝜖)&:𝑥_0→𝑎_𝑡𝑥_0+𝑏_𝑡𝜖\\𝑢_𝑡(𝑧|𝜖)&:=𝜓_{𝑡'}(𝜓_𝑡−1(𝑧|𝜖)|𝜖)
\end{aligned}
$$

- $z_t$가 초기 값이 $x_0$인 ODE $z'_t=u_t(z_t|\epsilon)$ 로 표현되기 때문에, $u_t(\cdot|\epsilon)$가 $p_t(\cdot|\epsilon)$을 생성할 수 있음.
- Conditional Vector Field $u_t(\cdot|\epsilon)$을 사용해서 Marginal Probability Path $p_t$ 를 생성하는 Marginal Vector Field $u_t$를 구성할 수 있음

$$
u_t(z) = \mathbb{E}_{\epsilon\sim\mathcal{N}(0, 1)}u_t(z|\epsilon){p_t(z|\epsilon)\over\ p_t(z)}
$$

- $u_t$를 회귀하는 동안 **Flow Matching objective는 다음과 같음**

$$
\mathcal{L}_{𝐹𝑀}=\mathbb{E}_{𝑡,𝑝_𝑡(𝑧)}||𝑣_Θ(𝑧,𝑡)−𝑢_𝑡(𝑧)||^2_2
$$

- `이것을 직접 사용하는 것은 Marginalization 때문에 직접 회귀하기 어려움`
    - Marginalization은 고차원 확률 분포에서 특정 변수를 제거하고 낮은 차원의 분포를 얻는 과정이며, 복잡한 계산 과정을 필요로 함
- Conditional Flow Matching에서는 조건부 벡터 필드 $u_t(z|\epsilon)$와 함께 사용하면 Equivalent 하면서 Tractable한 목표를 얻을 수 있음
    
    $$
    \mathcal{L}_{𝐶𝐹𝑀}=𝐸_{𝑡,𝑝_𝑡(𝑧|𝜖),𝑝(𝜖)}||𝑣_Θ(𝑧,𝑡)−𝑢_𝑡(𝑧|𝜖)||^2_2
    $$
    
- **손실 함수를 Explicit Form으로 변환하기 위하여 위의 식을 $t$에 대해 미분한 $\psi_t'(x_0|\epsilon) = a'_tx_0 + b'_0\epsilon$를 역함수로 변환한 $\psi^{-1}_t(z|\epsilon) = {z - b_t\epsilon\over a_t}$를 사용한다.**

$$
z_t' = u_t(z_t|\epsilon) = {a'_t \over a_t}z_t - \epsilon b_t({a_t' \over a_t} - {b_t'\over b_t})
$$

- **신호 대 잡음비율 (Signal-to-Noise Ratio, SNR) $𝜆_𝑡:=\log{⁡𝑎_𝑡^2 \over 𝑏_𝑡^2}, 𝜆'_t = 2({a_t' \over a_t} - {b_t'\over b_t})$ 을 고려할 때, 위의 식을 아래와 같이 쓸 수 있음**

$$
u_t(z_t|\epsilon) = {a'_t\over a_t}z_t - {b_t\over 2}\lambda_t'\epsilon
$$

- 위의 식을 사용해서 재매개화를 진행

$$
\begin{aligned}
\mathcal{L}_{𝐶𝐹𝑀} &= \mathbb{E}_{𝑡,𝑝𝑡(𝑧|𝜖),𝑝(𝜖)}||𝑣_Θ(𝑧,𝑡)−{𝑎_𝑡'\over 𝑎_𝑡}𝑧+{𝑏_𝑡 \over 2}𝜆_𝑡'𝜖||_2^2 \\
&=\mathbb{E}_{t, p_t(z|\epsilon), p(\epsilon)}(-{b_t \over 2} \lambda_t')^2||\epsilon_{\Theta}(z, t) - \epsilon||^2_2 \\

\end{aligned}
$$

 $where \quad \epsilon_\Theta = {-2\over \lambda'_t b_t}(v_{\Theta} - {a_t'\over a_t}z)$

- 시간에 따른 가중치를 도입해도 위 목표의 최적값은 변하지 않음.
- 따라서 원하는 솔루션을 향한 신호를 제공하지만 최적화 궤적에 영향을 줄 수 있는 다양한 가중치 손실 함수를 도출할 수 있음.
- 고전적인 확산 공식을 포함한 다양한 접근법을 통합적으로 분석하기 위해 다음과 같은 형태로 목표 함수를 작성할 수 있음

$$
\mathcal{L}_{w}(x_0) = 
-\frac{1}{2} E_{t\sim U(t), \epsilon \sim N(0, I)} [w_t \lambda't||\epsilon_{\Theta}(z_t, t) - \epsilon||^2] ] \\ where \quad 𝑤_𝑡=\frac{-1}{2}𝜆_𝑡'𝑏_𝑡^2
$$

# Flow Trajectories

이 섹션에서는 다양한 흐름 궤적 (Flow Trajectories) 공식화를 설명하고 이를 통해 생성 모델의 효율성을 높이는 방법을 다룹니다.

### Rectified Flow

- 데이터 분포와 표준 정규 분포를 직선 경로로 연결해줌.

$$
z_t = (1 - t)x_0 + tϵ
$$

- $\mathcal{L}_{CFM}$을 사용하면, $w_t^{RF} = \frac{t}{1-t}$로 대응됨. 네트워크 출력은 속도 $v_{\Theta}$를 직접 매개변수화 함.

`여기까지`

### EDM (Exponential Moving Average Diffusion)

- **특징**: 정규 분포의 양자 함수 \( F^{-1}_N \)을 사용하여 정의됩니다.
- **손실 함수**:
\[ L_{wEDM} \]

### Cosine Schedule

- **정의**:
\[ z_t = \cos\left(\frac{π}{2}t\right)x_0 + \sin\left(\frac{π}{2}t\right)ϵ \]
- **손실 함수**:
\[ w_t = \text{sech}\left(\frac{λ_t}{2}\right) \]

### LDM (Latent Diffusion Model) - Linear

- **정의**: 이산 시간 단계 \( t = 0, \ldots, T - 1 \)에서의 확산 계수를 사용하여 정의됩니다.
- **공식**:
\[ a_t = \left(\prod_{s=0}^{t}(1 - β_s)\right)^{\frac{1}{2}} \]

### 타겟 중간 단계에 대한 시간 샘플링 방법

### Logit-Normal Sampling

- **특징**: 중간 단계에 더 많은 가중치를 부여하는 분포입니다.
- **밀도**:
\[ π_{ln}(t; m, s) = \frac{1}{s\sqrt{2π}} \frac{1}{t(1 - t)} \exp\left(-\frac{(\text{logit}(t) - m)^2}{2s^2}\right) \]

### Mode Sampling with Heavy Tails

- **특징**: 전체 구간 [0, 1]에서 양의 밀도를 갖는 샘플링 분포입니다.
- **밀도**:
\[ π_{mode}(t; s) = \left| \frac{d}{dt} f^{-1}_{mode}(t) \right| \]

### CosMap

- **특징**: 코사인 스케줄과 일치하는 로그 신호 대 노이즈 비율을 얻기 위한 샘플링 방법입니다.
- **밀도**:
\[ π_{CosMap}(t) = \left| \frac{d}{dt} f^{-1}(t) \right| = \frac{2}{π - 2πt + 2πt^2} \]

### 결론

이 섹션에서는 다양한 흐름 궤적 공식화를 통해 생성 모델의 효율성을 높이는 방법을 제안합니다. 각각의 접근 방식은 특정 상황에서 더 나은 성능을 보일 수 있으며, 이를 통해 직류 흐름 모델의 샘플링 효율성을 극대화할 수 있습니다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/19fd67b1-0aa7-45f9-9b6d-a8b441f60733/e6761292-babd-4f26-8091-f2bc3a765f50/Untitled.png)

# Experiments

이 섹션에서는 제안된 방법의 성능을 평가하기 위한 실험 결과를 다룹니다.

### 5.1. Improving Rectified Flows

시뮬레이션 없이 Normalizing Flows를 훈련하는 다양한 접근법 중 어느 것이 가장 효율적인지 이해하는 것

**방법**:

- 61가지 공식화 변형을 ImageNet과 CC12M 데이터셋에서 훈련합니다.
- 각 모델의 최적의 스텝을 선택하고, 여러 샘플러 설정 하에서 CLIP 점수와 FID를 계산.
- 모든 설정에서 비지배적 정렬 알고리즘을 사용하여 공식화를 순위화합니다.

**결과**:

- **rf/lognorm(0.00, 1.00)**: 여러 설정에서 일관되게 좋은 순위를 기록했습니다.
- **rf/mode(1.75)**: 특정 설정에서 잘 작동하지만 다른 설정에서는 성능이 저하되었습니다.
- *rf/lognorm(0.00, 1.00)**이 전반적으로 안정적이며, 여러 메트릭과 데이터셋에서 우수한 성능을 보였습니다.

### 5.2. Improving Modality Specific Representations

**목적**: 고해상도 텍스트-이미지 합성을 위해 모델 아키텍처와 데이터 표현을 개선합니다.

**방법**:

1. **개선된 오토인코더**:
    - 더 많은 채널을 사용하여 재구성 성능을 향상시킵니다.
2. **개선된 캡션**:
    - 합성 캡션과 원본 캡션을 50:50 비율로 혼합하여 텍스트-이미지 성능을 향상시킵니다.
    - **GenEval** 벤치마크를 사용하여 성능을 평가합니다.
3. **개선된 텍스트-이미지 백본**:
    - **DiT, CrossDiT, UViT, MM-DiT** 아키텍처를 비교합니다.
    - **MM-DiT**는 텍스트와 이미지 토큰을 처리하는 두 개의 별도 가중치 세트를 사용하여 성능을 크게 향상시킵니다.

**결과**:

- **MM-DiT**: CrossDiT 및 UViT보다 우수한 성능을 보였습니다.
- **세트 개수**: 두 세트의 가중치를 사용하는 것이 세 세트의 가중치를 사용하는 것과 비슷한 성능을 보이면서도 더 효율적입니다.

### 5.3. Training at Scale

**목적**: 안전하고 효율적인 대규모 사전 훈련을 수행합니다.

**방법**:

1. **데이터 전처리**:
    - 성능 향상을 위해 데이터 필터링 및 사전 인코딩을 수행합니다.
2. **고해상도 파인튜닝**:
    - QK-정규화 및 위치 인코딩 조정으로 혼합 정밀도 훈련을 안정화합니다.
    - 시간 단계 이동 기법을 적용하여 더 높은 해상도로 훈련합니다.
3. **결과**:
    - 다양한 모델 크기로 500k 스텝 동안 훈련을 수행하고 검증 손실을 기록합니다.
    - 이미지와 비디오 도메인에서 모델 크기와 훈련 스텝에 따른 검증 손실 감소를 관찰합니다.
    - 검증 손실이 제안된 메트릭과 인간 선호 평가와 강하게 상관관계가 있음을 보입니다.

**결론**:

- 제안된 방법은 검증 손실 감소와 함께 전체적인 모델 성능을 향상시킵니다.
- 더 큰 모델은 더 적은 스텝으로도 우수한 성능을 보입니다.
- 제안된 아키텍처와 기법이 최신 비공개 모델과 경쟁할 수 있는 성능을 달성합니다.

# Conclusion

> 이 연구는 생성 모델링과 확장 가능한 멀티모달 아키텍처의 개선을 통해 최신 비공개 모델들과 경쟁할 수 있는 성능을 달성. 스케일링 트렌드가 포화되지 않음을 보여주며, 앞으로도 모델의 성능을 계속 향상시킬 수 있는 가능성을 시사함
> 
1. **새로운 타임스텝 샘플링**:
    - Rectified Flow 모델 훈련을 위한 새로운 타임스텝 샘플링 기법을 제안하여, 이전의 확산 모델 훈련 공식보다 향상된 성능을 보임.
    - 특히, few-shot 샘플링 스텝에서 우수한 성능을 유지할 수 있는 직류 흐름의 유리한 특성을 유지.
2. **멀티모달 트랜스포머 기반 아키텍처**:
    - 텍스트와 이미지 간의 다중 모달 특성을 고려한 새로운 트랜스포머 기반 아키텍처인 MM-DiT를 제안하여, 텍스트-이미지 합성 성능을 크게 향상시킴.
3. **스케일링 연구**:
    - 최대 80억 개의 파라미터와 5x10^22 FLOPs의 훈련량을 가진 모델을 포함한 스케일링 연구를 수행.
    - 검증 손실의 감소가 기존의 텍스트-이미지 벤치마크와 인간 선호 평가와 상관관계가 있음을 보였음.