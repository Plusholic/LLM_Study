# Abstract

> **확산 모델 (Diffusion Models)은** 데이터에서 노이즈로의 경로를 반전시켜 데이터를 생성하는 기법. 고차원 및 Perceptual Data(이미지, 비디오 등)를 생성하는 강력한 기법으로 부상하였음. **Rectified Flow는** 데이터와 노이즈를 직선으로 연결하는 새로운 생성 모델 방식으로, 이론적으로 더 우수하지만 아직 널리 사용되지 않았음.
> 
- Rectified Flow 모델 훈련을 위해 지각적으로 관련 있는 스케일로 편향된 노이즈 샘플링 기법을 도입.
- Text-to-Image 생성을 위한 새로운 트랜스포머 기반 아키텍처를 제시. 이 아키텍처는 두 가지 모달리티(텍스트와 이미지)에 대해 별도의 가중치를 사용하고, 이미지와 텍스트 토큰 간의 양방향 정보 흐름을 가능하게 하여 텍스트 이해, 타이포그래피, 그리고 사람 선호도 평가를 개선함.
- **모델 확장성**을 예측 가능한 스케일링 트렌드를 따르며, Lower Validation Loss가 더 나은 Text-to-Image systhesis 성능과 상관관계가 있음을 보임.
- **기존 최고 수준의 모델보다 우수함**을 증명하고, 실험 데이터, 코드 및 모델 가중치를 공개할 예정.

# Introduction

> 확산 모델은 노이즈에서 데이터를 생성합니다, 그들은 데이터의 정방향 경로를 역전시키기 위해 훈련되어 무작위 노이즈로 변환됨. 따라서 신경망의 근사화 및 일반화 특성과 결합하여 훈련 데이터에는 존재하지 않지만 `훈련 데이터의 분포를 따르는 새로운 데이터 포인트를 생성하는 데 사용될 수 있음`. 데이터에서 노이즈로의 전방 경로를 지정하는 것은 효율적인 훈련을 이끌어내지만, 어떤 경로를 선택해야 하는지에 대한 문제가 생김. 예를 들어, 데이터에서 모든 노이즈를 제거하지 못하는 전방 과정은 훈련 및 테스트 분포의 불일치를 초래하고 회색 이미지 샘플과 같은 아티팩트를 초래할 수 있음. 중요한 점은 전방 과정의 선택이 역방향 과정 및 샘플링 효율성에도 영향을 준다는 것임. 곡선 경로는 프로세스를 시뮬레이션하기 위해 많은 통합 단계를 필요로 하지만, 직선 경로는 단일 단계로 시뮬레이션할 수 있으며 오류 누적 가능성이 적다. 각 단계가 신경망의 평가에 해당하기 때문에 이는 샘플링 속도에 직접적인 영향을 주게 됨.
> 
- 특정한 선택인 Forward path의 경우, Recitified Flow라고 불리는 것이 있음. 이는 데이터와 노이즈를 직선으로 연결. 이 모델 클래스는 이론적 특성이 더 우수하지만, 아직 실무에서 명확하게 확립되지는 않았음
- 본 연구에서는 이를 바꾸기 위해 Recitified flow 모델에서 노이즈 스케일을 재조정하여 소음 예측 확산 모델과 유사한 방식으로 소개.
- 모델에 이미지 및 텍스트 토큰에 대한 학습 가능한 스트림을 통합하는 새로운 아키텍처를 제시하고, 이를 통해 두 가지 정보 간에 양방향 흐름을 가능하게 함.
- 이를 개선된 정류된 흐름 공식과 결합하고, 그 확장성을 조사합니다. 검증 손실에서 예측 가능한 스케일링 경향을 보여주며, 낮은 검증 손실이 향상된 자동 및 인간 평가와 강한 상관 관계가 있음을 보여줌.

### 핵심 기여

1. 다양한 확산 모델 및 Recitified Flow 공식에 대한 대규모 체계적 연구를 수행하여 최적 설정을 식별. 이를 위해, 우리는 이전에 알려진 샘플러보다 성능을 향상시키는 교정된 플로우 모델을 위한 새로운 노이즈 샘플러를 소개.
2. 텍스트에서 이미지로의 합성을 위한 혁신적이고 확장 가능한 아키텍처를 고안함. 이 아키텍처는 네트워크 내에서 텍스트 및 이미지 토큰 스트림 간의 양방향 혼합을 허용.
3. 모델의 스케일링 연구를 수행하고 예측 가능한 스케일링 트렌드를 보여줌. 우리는 낮은 검증 손실이 T2I-CompBench (Huang et al., 2023), GenEval (Ghosh et al., 2023) 및 인간 평가와 같은 메트릭을 통해 평가된 텍스트에서 이미지로의 성능 향상과 강한 상관 관계가 있음을 보여줌.

# Simulation-Free Training of Flows 요약

이 섹션에서는 노이즈 분포 \( p_1 \)에서 데이터 분포 \( p_0 \)로 샘플을 변환하는 생성 모델을 다룹니다. 이를 위해 Ordinary Differential Equation (ODE)을 사용하여 다음과 같이 정의합니다:

\[ dyt = vΘ(yt, t) dt \]

여기서 \( v \)는 신경망의 가중치 \( Θ \)에 의해 매개변수가 설정된 속도입니다. 이전 연구는 ODE 솔버를 통해 이 방정식을 직접 해결하는 방법을 제안했지만, 이는 대규모 네트워크 아키텍처에 대해 계산적으로 비효율적입니다.

### 대안 방법:

1. **직접 회귀**: 확률 경로를 생성하는 벡터 필드 \( ut \)를 직접 회귀하는 방식이 제안되었습니다. 이를 위해 다음과 같은 확률 경로 \( pt \)를 정의합니다:

\[ zt = atx0 + btϵ \]

여기서 \( ϵ \sim N(0, I) \).

1. **조건부 벡터 필드**: \( ut \)는 조건부 벡터 필드 \( ut(z|ϵ) \)를 사용하여 생성됩니다:

\[ ut(z|ϵ) := ψ′_t(ψ^{-1}_t(z|ϵ)|ϵ) \]

이를 통해 \( zt \)는 ODE의 해로 나타낼 수 있으며, 이는 \( z0 = x0 \)로 시작합니다.

### 손실 함수:

- **Flow Matching Objective (LFM)**:

\[ LFM = Et,pt(z)||vΘ(z, t)− ut(z)||^2_2 \]

이 방식은 직접적으로 구현하기 어렵기 때문에, 조건부 Flow Matching (LCFM) 방식이 제안되었습니다:

\[ LCFM = Et,pt(z|ϵ),p(ϵ)||vΘ(z, t)− ut(z|ϵ)||^2_2 \]

### 재매개변수화:

- **신호 대 노이즈 비율 (SNR)**:

\[ λt := \log \frac{a^2_t}{b^2_t} \]

이를 통해 노이즈 예측 목적을 위한 재매개변수화가 이루어집니다.

### 다양한 접근 방식:

1. **Rectified Flow (RF)**:

\[ zt = (1 - t)x0 + tϵ \]

1. **EDM**:

\[ zt = x0 + btϵ \]

여기서 \( bt \)는 정규 분포의 양자 함수로 정의됩니다.

1. **Cosine Schedule**:

\[ zt = \cos(\frac{π}{2}t)x0 + \sin(\frac{π}{2}t)ϵ \]

이 외에도 다양한 샘플링 분포와 가중치 손실 함수가 제안되었습니다.

### 결론:

이 섹션에서는 여러 접근 방식을 비교하고, 직류 흐름 모델의 효율성을 높이기 위한 다양한 샘플링 및 손실 함수 기법을 제안하였습니다. 이를 통해 더 나은 생성 모델링 성능을 달성할 수 있습니다.

# Flow Trajectories

이 섹션에서는 다양한 흐름 궤적 (Flow Trajectories) 공식화를 설명하고 이를 통해 생성 모델의 효율성을 높이는 방법을 다룹니다.

### Rectified Flow

- **정의**: 데이터 분포와 표준 정규 분포를 직선 경로로 연결합니다.
- **공식**:
\[ z_t = (1 - t)x_0 + tϵ \]
- **손실 함수**:
\[ L_{CFM} \]

### EDM (Exponential Moving Average Diffusion)

- **정의**:
\[ z_t = x_0 + b_tϵ \]
- **특징**: 정규 분포의 양자 함수 \( F^{-1}_N \)을 사용하여 정의됩니다.
- **손실 함수**:
\[ L_{wEDM} \]

### Cosine Schedule

- **정의**:
\[ z_t = \cos\left(\frac{π}{2}t\right)x_0 + \sin\left(\frac{π}{2}t\right)ϵ \]
- **손실 함수**:
\[ w_t = \text{sech}\left(\frac{λ_t}{2}\right) \]

### LDM (Latent Diffusion Model) - Linear

- **정의**: 이산 시간 단계 \( t = 0, \ldots, T - 1 \)에서의 확산 계수를 사용하여 정의됩니다.
- **공식**:
\[ a_t = \left(\prod_{s=0}^{t}(1 - β_s)\right)^{\frac{1}{2}} \]

### 타겟 중간 단계에 대한 시간 샘플링 방법

### Logit-Normal Sampling

- **특징**: 중간 단계에 더 많은 가중치를 부여하는 분포입니다.
- **밀도**:
\[ π_{ln}(t; m, s) = \frac{1}{s\sqrt{2π}} \frac{1}{t(1 - t)} \exp\left(-\frac{(\text{logit}(t) - m)^2}{2s^2}\right) \]

### Mode Sampling with Heavy Tails

- **특징**: 전체 구간 [0, 1]에서 양의 밀도를 갖는 샘플링 분포입니다.
- **밀도**:
\[ π_{mode}(t; s) = \left| \frac{d}{dt} f^{-1}_{mode}(t) \right| \]

### CosMap

- **특징**: 코사인 스케줄과 일치하는 로그 신호 대 노이즈 비율을 얻기 위한 샘플링 방법입니다.
- **밀도**:
\[ π_{CosMap}(t) = \left| \frac{d}{dt} f^{-1}(t) \right| = \frac{2}{π - 2πt + 2πt^2} \]

### 결론

이 섹션에서는 다양한 흐름 궤적 공식화를 통해 생성 모델의 효율성을 높이는 방법을 제안합니다. 각각의 접근 방식은 특정 상황에서 더 나은 성능을 보일 수 있으며, 이를 통해 직류 흐름 모델의 샘플링 효율성을 극대화할 수 있습니다.

# Experiments

이 섹션에서는 제안된 방법의 성능을 평가하기 위한 실험 결과를 다룹니다.

### 5.1. Improving Rectified Flows

**목적**: 다양한 시뮬레이션 없는 정규화 흐름 공식화를 비교하여 가장 효율적인 설정을 식별합니다.

**방법**:

- 61가지 공식화 변형을 ImageNet과 CC12M 데이터셋에서 훈련합니다.
- 각 모델의 최적의 스텝을 선택하고, 여러 샘플러 설정 하에서 CLIP 점수와 FID를 계산합니다.
- 모든 설정에서 비지배적 정렬 알고리즘을 사용하여 공식화를 순위화합니다.

**결과**:

- **rf/lognorm(0.00, 1.00)**: 여러 설정에서 일관되게 좋은 순위를 기록했습니다.
- **rf/mode(1.75)**: 특정 설정에서 잘 작동하지만 다른 설정에서는 성능이 저하되었습니다.
- *rf/lognorm(0.00, 1.00)**이 전반적으로 안정적이며, 여러 메트릭과 데이터셋에서 우수한 성능을 보였습니다.

### 5.2. Improving Modality Specific Representations

**목적**: 고해상도 텍스트-이미지 합성을 위해 모델 아키텍처와 데이터 표현을 개선합니다.

**방법**:

1. **개선된 오토인코더**:
    - 더 많은 채널을 사용하여 재구성 성능을 향상시킵니다.
2. **개선된 캡션**:
    - 합성 캡션과 원본 캡션을 50:50 비율로 혼합하여 텍스트-이미지 성능을 향상시킵니다.
    - **GenEval** 벤치마크를 사용하여 성능을 평가합니다.
3. **개선된 텍스트-이미지 백본**:
    - **DiT, CrossDiT, UViT, MM-DiT** 아키텍처를 비교합니다.
    - **MM-DiT**는 텍스트와 이미지 토큰을 처리하는 두 개의 별도 가중치 세트를 사용하여 성능을 크게 향상시킵니다.

**결과**:

- **MM-DiT**: CrossDiT 및 UViT보다 우수한 성능을 보였습니다.
- **세트 개수**: 두 세트의 가중치를 사용하는 것이 세 세트의 가중치를 사용하는 것과 비슷한 성능을 보이면서도 더 효율적입니다.

### 5.3. Training at Scale

**목적**: 안전하고 효율적인 대규모 사전 훈련을 수행합니다.

**방법**:

1. **데이터 전처리**:
    - 성능 향상을 위해 데이터 필터링 및 사전 인코딩을 수행합니다.
2. **고해상도 파인튜닝**:
    - QK-정규화 및 위치 인코딩 조정으로 혼합 정밀도 훈련을 안정화합니다.
    - 시간 단계 이동 기법을 적용하여 더 높은 해상도로 훈련합니다.
3. **결과**:
    - 다양한 모델 크기로 500k 스텝 동안 훈련을 수행하고 검증 손실을 기록합니다.
    - 이미지와 비디오 도메인에서 모델 크기와 훈련 스텝에 따른 검증 손실 감소를 관찰합니다.
    - 검증 손실이 제안된 메트릭과 인간 선호 평가와 강하게 상관관계가 있음을 보입니다.

**결론**:

- 제안된 방법은 검증 손실 감소와 함께 전체적인 모델 성능을 향상시킵니다.
- 더 큰 모델은 더 적은 스텝으로도 우수한 성능을 보입니다.
- 제안된 아키텍처와 기법이 최신 비공개 모델과 경쟁할 수 있는 성능을 달성합니다.

# Conclusion 요약

이 논문은 텍스트-이미지 합성을 위한 Rectified Flow 모델의 스케일링 분석을 제시합니다. 주요 결론은 다음과 같습니다:

1. **새로운 타임스텝 샘플링**:
    - 직류 흐름 모델 훈련을 위한 새로운 타임스텝 샘플링 기법을 제안하여, 이전의 확산 모델 훈련 공식보다 향상된 성능을 보입니다.
    - 특히, 소수의 샘플링 스텝에서 우수한 성능을 유지할 수 있는 직류 흐름의 유리한 특성을 유지합니다.
2. **멀티모달 트랜스포머 기반 아키텍처**:
    - 텍스트와 이미지 간의 다중 모달 특성을 고려한 새로운 트랜스포머 기반 아키텍처인 MM-DiT를 제안하여, 텍스트-이미지 합성 성능을 크게 향상시킵니다.
3. **스케일링 연구**:
    - 최대 80억 개의 파라미터와 5x10^22 FLOPs의 훈련량을 가진 모델을 포함한 스케일링 연구를 수행했습니다.
    - 검증 손실의 감소가 기존의 텍스트-이미지 벤치마크와 인간 선호 평가와 상관관계가 있음을 보였습니다.
4. **공개 계획**:
    - 실험 데이터, 코드, 모델 가중치를 공개할 예정입니다.

### 요약

이 연구는 생성 모델링과 확장 가능한 멀티모달 아키텍처의 개선을 통해 최신 비공개 모델들과 경쟁할 수 있는 성능을 달성했습니다. 스케일링 트렌드가 포화되지 않음을 보여주며, 앞으로도 모델의 성능을 계속 향상시킬 수 있는 가능성을 시사합니다.