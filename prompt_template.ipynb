{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='GNN stands for Graph Neural Network. It is a type of neural network that is specifically designed for processing data structured as graphs. \\n\\nTraditional neural networks are designed to process data in a tabular format or as sequences, but they struggle when it comes to handling graph-structured data. Graphs are a powerful way to represent relationships between entities, such as social networks, molecular structures, or recommendation systems. GNNs are designed to leverage these relationships to make more accurate predictions or classifications.\\n\\nGNNs operate by propagating information through the graph structure. Each node in the graph is associated with a feature vector, and the network updates these vectors based on the information from neighboring nodes. This way, the network can capture the local and global patterns within the graph.\\n\\nThe key advantage of GNNs is their ability to capture both the structural information of the graph and the node-level features. This makes them particularly useful for tasks such as node classification, link prediction, and graph generation.\\n\\nGNNs have gained significant attention in recent years due to their success in various domains, including social network analysis, recommendation systems, and bioinformatics. Researchers continue to explore new architectures and techniques to further improve the performance of GNNs and extend their applications.\\n\\nOverall, GNNs are a powerful tool for analyzing and understanding graph-structured data, enabling more accurate predictions and insights in various domains.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI bot\"),\n",
    "    # (\"human\", \"Hello, how are you doing?\"),\n",
    "    # (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    user_input=\"I want to know about GNN\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I absolutely love indulging in delicious treats!')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.schema.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant that re-writes the user's text to \"\n",
    "                \"sound more upbeat.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm(chat_template.format_messages(text='i dont like eating tasty things.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_llm 함수 -> Conversationall_Retrieval_qa로 변경\n",
    "질문 여러개 생성해서 조합해서 답변하는거 테스트하기\n",
    "\n",
    "다운받을 수 있는 링크 추가\n",
    "검색하는 갯수 k개 추가 -> done, 문제가 있음. k가 커질수록 모델이 헷갈려 함.\n",
    "같은 논문이면 page만 따로 출력하도록 해야 함\n",
    "\n",
    "https://github.com/pragmatic-streamlit/streamlit-file-browser\n",
    "이거 추가해야 함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('LLM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a3a50cfa768e55079b834244adbc23d62a4b24bbd2f8b443e30bd8c79d3f7ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
